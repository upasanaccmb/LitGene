{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from transformers import AdamW\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
    "\n",
    "from torch.nn import TripletMarginLoss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "# import mplcursors\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "import networkx as nx\n",
    "import obonet\n",
    "from collections import Counter\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateFusion(nn.Module):\n",
    "    def __init__(self, in1=768, in2=200, hidden_size=500, out = 768):\n",
    "        super(Gene2VecFusionModel, self).__init__()\n",
    "        \n",
    "        self.embedding1 = nn.Linear(in1, hidden_size) #BERT\n",
    "        \n",
    "        \n",
    "        self.embedding2 = nn.Linear(in2, in2) \n",
    "        self.unet1 = nn.Linear(in2, hidden_size)\n",
    "        self.unet2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.unet3 = nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        #For BERT\n",
    "        x1 = self.embedding1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "                \n",
    "        \n",
    "        #For other modalities\n",
    "        x2 = self.embedding2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        \n",
    "        x2 = self.unet1(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        \n",
    "        x2 = self.unet2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        \n",
    "        x2 = self.unet3(x2)\n",
    "        x2 = self.relu(x2)\n",
    "\n",
    "        \n",
    "        z = torch.cat((x1, x2), dim=1)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.relu(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, input_size=768, hidden_size=500, n_labels=1):\n",
    "        super(FusionModel, self).__init__()\n",
    "        \n",
    "        self.embedding1 = nn.Linear(input_size, hidden_size)\n",
    "        self.embedding2 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, n_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.embedding1(x1)\n",
    "        x2 = self.embedding2(x2)\n",
    "        \n",
    "        z = torch.cat((x1, x2), dim=1)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.sigmoid(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "class Gene2VecFusionModel(nn.Module):\n",
    "    def __init__(self, in1=768, in2=200, hidden_size=500, out = 768):\n",
    "        super(Gene2VecFusionModel, self).__init__()\n",
    "        \n",
    "        self.embedding1 = nn.Linear(in1, hidden_size)\n",
    "        self.embedding2 = nn.Linear(in2, hidden_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.embedding1(x1)\n",
    "        x2 = self.embedding2(x2)\n",
    "        \n",
    "        z = torch.cat((x1, x2), dim=1)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.relu(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "class MultiLabelFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, reduction='mean'):\n",
    "        super(MultiLabelFocalLoss, self).__init__()\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.tensor(0.25, requires_grad=True, device=\"cuda\"))  \n",
    "        self.gamma = nn.Parameter(torch.tensor(2.0, requires_grad=True, device=\"cuda\"))  \n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss) \n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        return F_loss.mean()\n",
    "\n",
    "class FineTunedBERT(nn.Module):\n",
    "\n",
    "    def __init__(self, pool=\"mean\", model_name= \"bert-base-cased\", bert_state_dict=None,\n",
    "                 task_type = None, n_labels = None, drop_rate = None,\n",
    "                 gene2vec_flag=None, gene2vec_hidden = 200, device =\"cuda\"):\n",
    "        \n",
    "        \"\"\"\n",
    "            task_type : regression or classification.\n",
    "        \n",
    "        \"\"\"\n",
    "      \n",
    "        super(FineTunedBERT, self).__init__()\n",
    "\n",
    "#         assert (task_type == 'unsupervised' and n_labels == 1) or (task_type == 'regression' and n_labels == 1) or (task_type == 'classification' and n_labels>1) or (task_type == 'multilabel' and n_labels>1), \\\n",
    "#             f\"Invalid combination of task_type and n_labels: {task_type} and {n_labels}\"  \n",
    "\n",
    "#         assert gene2vec_flag is not None, f\"gene2vec_flag cannot be None: {gene2vec_flag}\"\n",
    "\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.pool = pool\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"xlnet\" in model_name:\n",
    "            self.bert = XLNetModel.from_pretrained(model_name).to(device)\n",
    "        \n",
    "        else:\n",
    "            if bert_state_dict: \n",
    "                self.bert = AutoModel.from_pretrained(model_name)\n",
    "                self.bert.load_state_dict(bert_state_dict) #.to(device)\n",
    "            else:\n",
    "                self.bert = AutoModel.from_pretrained(model_name)#.to(device)\n",
    "                \n",
    "        \n",
    "#         layers_to_train = [\"encoder.layer.11\", \"encoder.layer.10\", \"encoder.layer.9\",\n",
    "#                            \"encoder.layer.8\",\"pooler\"]\n",
    "        for name, param in self.bert.named_parameters():\n",
    "\n",
    "            if name.startswith(\"encoder.layer.11\") or name.startswith(\"encoder.layer.10\") or\\\n",
    "            name.startswith(\"encoder.layer.9\") or name.startswith(\"pooler\") or\\\n",
    "            name.startswith(\"encoder.layer.8\") : \n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "        \n",
    "        \n",
    "        self.bert_hidden = self.bert.config.hidden_size\n",
    "        self.gene2vecFusion = Gene2VecFusionModel(in1=self.bert_hidden,\n",
    "                                                  in2=gene2vec_hidden,\n",
    "                                                  hidden_size=500,\n",
    "                                                  out = self.bert_hidden)\n",
    "        \n",
    "        if task_type.lower() == \"classification\":\n",
    "            \n",
    "            assert  n_labels > 1, f\"Invalid combination of task_type and n_labels: {task_type} and {n_labels}\"\n",
    "            self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, n_labels))\n",
    "#             if gene2vec_flag:\n",
    "#                 self.pipeline = nn.Sequential(\n",
    "#                     nn.Linear(self.bert_hidden+gene2vec_hidden, n_labels)\n",
    "#                 )\n",
    "                \n",
    "#             else:\n",
    "#                 self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, n_labels))\n",
    "    \n",
    "        elif task_type.lower() == \"multilabel\":\n",
    "            assert  n_labels > 1, f\"Invalid combination of task_type and n_labels: {task_type} and {n_labels}\"\n",
    "            self.pipeline = nn.Sequential(\n",
    "                    nn.Linear(self.bert_hidden, n_labels),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "            \n",
    "#             assert  n_labels > 1, f\"Invalid combination of task_type and n_labels: {task_type} and {n_labels}\"\n",
    "            \n",
    "#             if gene2vec_flag:\n",
    "#                 self.pipeline = nn.Sequential(\n",
    "#                     nn.Linear(self.bert_hidden+gene2vec_hidden, n_labels),\n",
    "#                     nn.Sigmoid()\n",
    "#                 )\n",
    "                \n",
    "#             else:\n",
    "#                 self.pipeline = nn.Sequential(\n",
    "#                     nn.Linear(self.bert_hidden, n_labels),\n",
    "#                     nn.Sigmoid()\n",
    "#                 )\n",
    "\n",
    "        elif task_type.lower() == \"regression\":\n",
    "            assert  n_labels == 1, f\"Invalid combination of task_type and n_labels: {task_type} and {n_labels}\"\n",
    "            self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, 1))\n",
    "            \n",
    "\n",
    "#             if gene2vec_flag:\n",
    "#                 self.pipeline = nn.Sequential(\n",
    "#                 nn.Linear(self.bert_hidden+gene2vec_hidden, 1))\n",
    "                \n",
    "#             else:            \n",
    "#                 self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, 1))\n",
    "        \n",
    "        elif task_type.lower() ==\"interaction\":\n",
    "            if gene2vec_flag:\n",
    "                raise ValueError(f\"gene2vec_flag must be False when task_type is set to {task_type}: {gene2vec_flag=}\")\n",
    "                \n",
    "            else:      \n",
    "                self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, 1))\n",
    "            \n",
    "        \n",
    "        elif task_type.lower() == \"unsupervised\":\n",
    "            self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, 1))\n",
    "            #No need for an assert, labels will not be used during unsupervised.\n",
    "\n",
    "#             if gene2vec_flag:\n",
    "#                 raise ValueError(f\"gene2vec_flag must be False when task_type is set to {task_type}: {gene2vec_flag=}\")\n",
    "                \n",
    "#             else:      \n",
    "#                 self.pipeline = nn.Sequential(nn.Linear(self.bert_hidden, 1))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Key Error task_type : {task_type} \")\n",
    "          \n",
    "    def forward(self, input_ids_, attention_mask_, gene2vec=None):\n",
    "        \n",
    "        \n",
    "        # retrieving the hidden state embeddings\n",
    "        if \"xlnet\" in self.model_name:\n",
    "            output = self.bert(input_ids = input_ids_,\n",
    "                               attention_mask=attention_mask_)\n",
    "\n",
    "            hiddenState, ClsPooled = output.last_hidden_state, output.last_hidden_state[:,0, :]\n",
    "\n",
    "        else:\n",
    "            hiddenState, ClsPooled = self.bert(input_ids = input_ids_,\n",
    "                                               attention_mask=attention_mask_).values()\n",
    "\n",
    "        \n",
    "        # perform pooling on the hidden state embeddings\n",
    "        if self.pool.lower() == \"max\":\n",
    "            embeddings = self.max_pooling(hiddenState, attention_mask_)\n",
    "            \n",
    "        elif self.pool.lower() == \"cls\":\n",
    "            embeddings = ClsPooled\n",
    "                \n",
    "        elif self.pool.lower() == \"mean\":\n",
    "            embeddings = self.mean_pooling(hiddenState, attention_mask_)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Pooling value error.')\n",
    "        \n",
    "        \n",
    "        if gene2vec is not None:\n",
    "            embeddings = self.gene2vecFusion(embeddings, gene2vec)\n",
    "            #embeddings = torch.cat((embeddings, gene2vec), dim=1)\n",
    "      \n",
    "\n",
    "        return embeddings, hiddenState, self.pipeline(embeddings)\n",
    "\n",
    "    def max_pooling(self, hidden_state, attention_mask):\n",
    "        \n",
    "        #CLS: First element of model_output contains all token embeddings\n",
    "        token_embeddings = hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "        \n",
    "        pooled_embeddings = torch.max(token_embeddings, 1)[0]\n",
    "        return pooled_embeddings\n",
    "    \n",
    "    def mean_pooling (self, hidden_state, attention_mask):\n",
    "        \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n",
    "        pooled_embeddings = torch.sum(hidden_state * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9) \n",
    "        \n",
    "        return pooled_embeddings\n",
    "    \n",
    "def getEmbeddings(text,\n",
    "                  model = None,\n",
    "                  model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    "                  max_length=512,\n",
    "                  batch_size=1000,\n",
    "                  gene2vec_flag=False,\n",
    "                  gene2vec_hidden=200,\n",
    "                  pool =\"mean\"):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if isinstance(model, FineTunedBERT):\n",
    "        print(\"Loading a pretrained model ...\")\n",
    "        \n",
    "        model_name = model.model_name            \n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    \n",
    "    elif isinstance(model, collections.OrderedDict):\n",
    "        print(\"Loading a pretrained model from a state dictionary ...\")\n",
    "        \n",
    "        state_dict = model.copy() \n",
    "        \n",
    "        model = FineTunedBERT(pool= pool,model_name = model_name,\n",
    "                              gene2vec_flag= gene2vec_flag,\n",
    "                              gene2vec_hidden = gene2vec_hidden,\n",
    "                              task_type=\"unsupervised\",\n",
    "                              n_labels = 1,\n",
    "                              device = device).to(device)\n",
    "\n",
    "        \n",
    "        for s in model.state_dict().keys():\n",
    "            if s not in state_dict.keys():\n",
    "                print(s)\n",
    "        \n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "            \n",
    "    else:\n",
    "        print(\"Creating a new pretrained model ...\")\n",
    "        \n",
    "        #BERT-base embeddings\n",
    "        model = FineTunedBERT(pool= pool,\n",
    "                              model_name=model_name,\n",
    "                              task_type=\"unsupervised\",\n",
    "                              gene2vec_flag = False,\n",
    "                              n_labels = 1).to(device)\n",
    "  \n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    print(\"Tokenization ...\")\n",
    "    tokens = tokenizer.batch_encode_plus(text, max_length = max_length,\n",
    "                                         padding=\"max_length\",truncation=True,\n",
    "                                         return_tensors=\"pt\")\n",
    "    \n",
    "    \n",
    "    dataset = TensorDataset(tokens[\"input_ids\"] , tokens[\"attention_mask\"])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"Tokenization Done.\")\n",
    "    \n",
    "    print(\"Get Embeddings ...\")\n",
    "    \n",
    "    embeddings=[]\n",
    "    model.eval()\n",
    "    for batch_input_ids, batch_attention_mask in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            pooled_embeddings, _, _ = model(batch_input_ids.to(device) ,\n",
    "                                            batch_attention_mask.to(device))\n",
    "            embeddings.append(pooled_embeddings)\n",
    "    \n",
    "    \n",
    "    concat_embeddings = torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    print(concat_embeddings.size())\n",
    "    \n",
    "    return concat_embeddings\n",
    "\n",
    "def getEmbeddingsWithGene2Vec(dataloader, model):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    embeddings=[]\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            batch_inputs_a, batch_masks_a, gene2vec_a  =  batch[0].to(device) , batch[1].to(device), batch[2].to(device)\n",
    "            pooled_embeddings, _ , _ = model(batch_inputs_a, batch_masks_a, gene2vec =gene2vec_a)\n",
    "            embeddings.append(pooled_embeddings)\n",
    "    \n",
    "    \n",
    "    concat_embeddings = torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    print(concat_embeddings.size())\n",
    "    \n",
    "    return concat_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(text,\n",
    "                  model = None,\n",
    "                  model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    "                  max_length=512,\n",
    "                  batch_size=1000,\n",
    "                  gene2vec_flag=False,\n",
    "                  gene2vec_hidden=200,\n",
    "                  pool =\"mean\"):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if isinstance(model, FineTunedBERT):\n",
    "        print(\"Loading a pretrained model ...\")\n",
    "        \n",
    "        model_name = model.model_name            \n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    \n",
    "    elif isinstance(model, collections.OrderedDict):\n",
    "        print(\"Loading a pretrained model from a state dictionary ...\")\n",
    "        \n",
    "        state_dict = model.copy() \n",
    "        \n",
    "        model = FineTunedBERT(pool= pool,model_name = model_name,\n",
    "                              gene2vec_flag= gene2vec_flag,\n",
    "                              gene2vec_hidden = gene2vec_hidden,\n",
    "                              task_type=\"unsupervised\",\n",
    "                              n_labels = 1,\n",
    "                              device = device).to(device)\n",
    "\n",
    "        \n",
    "        for s in model.state_dict().keys():\n",
    "            if s not in state_dict.keys():\n",
    "                print(s)\n",
    "        \n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "            \n",
    "    else:\n",
    "        print(\"Creating a new pretrained model ...\")\n",
    "        \n",
    "        #BERT-base embeddings\n",
    "        model = FineTunedBERT(pool= pool,\n",
    "                              model_name=model_name,\n",
    "                              task_type=\"unsupervised\",\n",
    "                              gene2vec_flag = False,\n",
    "                              n_labels = 1).to(device)\n",
    "  \n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    print(\"Tokenization ...\")\n",
    "    tokens = tokenizer.batch_encode_plus(text, max_length = max_length,\n",
    "                                         padding=\"max_length\",truncation=True,\n",
    "                                         return_tensors=\"pt\")\n",
    "    \n",
    "    \n",
    "    dataset = TensorDataset(tokens[\"input_ids\"] , tokens[\"attention_mask\"])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"Tokenization Done.\")\n",
    "    \n",
    "    print(\"Get Embeddings ...\")\n",
    "    \n",
    "    embeddings=[]\n",
    "    model.eval()\n",
    "    for batch_input_ids, batch_attention_mask in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            pooled_embeddings, _, _ = model(batch_input_ids.to(device) ,\n",
    "                                            batch_attention_mask.to(device))\n",
    "            embeddings.append(pooled_embeddings)\n",
    "    \n",
    "    \n",
    "    concat_embeddings = torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    print(concat_embeddings.size())\n",
    "    \n",
    "    return concat_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEP</td>\n",
       "      <td>0.758912</td>\n",
       "      <td>obesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THRSP</td>\n",
       "      <td>0.741904</td>\n",
       "      <td>obesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAZF1</td>\n",
       "      <td>0.720466</td>\n",
       "      <td>obesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1QTNF12</td>\n",
       "      <td>0.711311</td>\n",
       "      <td>obesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEPROT</td>\n",
       "      <td>0.708792</td>\n",
       "      <td>obesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>TRPC3</td>\n",
       "      <td>0.560457</td>\n",
       "      <td>hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GPR182</td>\n",
       "      <td>0.560197</td>\n",
       "      <td>hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>0.558525</td>\n",
       "      <td>hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>CD36</td>\n",
       "      <td>0.558066</td>\n",
       "      <td>hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>PRKCE</td>\n",
       "      <td>0.558050</td>\n",
       "      <td>hypertension</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene  Cosine Similarity       Disease\n",
       "0         LEP           0.758912       obesity\n",
       "1       THRSP           0.741904       obesity\n",
       "2       JAZF1           0.720466       obesity\n",
       "3    C1QTNF12           0.711311       obesity\n",
       "4      LEPROT           0.708792       obesity\n",
       "..        ...                ...           ...\n",
       "395     TRPC3           0.560457  hypertension\n",
       "396    GPR182           0.560197  hypertension\n",
       "397    KCNK18           0.558525  hypertension\n",
       "398      CD36           0.558066  hypertension\n",
       "399     PRKCE           0.558050  hypertension\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_obesity = pd.read_csv('/data_link/macaulay/GeneLLM2/diseaseAssociation/cosineSimilarity/cosine_similarities_not_in_obesity.csv')    \n",
    "df_obesity = df_obesity.iloc[:100]\n",
    "\n",
    "df_asthma = pd.read_csv('/data_link/macaulay/GeneLLM2/diseaseAssociation/cosineSimilarity/cosine_similarities_not_in_asthma.csv')    \n",
    "df_asthma = df_asthma.iloc[:100]\n",
    "\n",
    "df_schizophrenia = pd.read_csv('/data_link/macaulay/GeneLLM2/diseaseAssociation/cosineSimilarity/cosine_similarities_not_in_schizophrenia.csv')    \n",
    "df_schizophrenia = df_schizophrenia.iloc[:100]\n",
    "\n",
    "df_hypertension = pd.read_csv('/data_link/macaulay/GeneLLM2/diseaseAssociation/cosineSimilarity/cosine_similarities_not_in_hypertension.csv')    \n",
    "df_hypertension = df_hypertension.iloc[:100]\n",
    "\n",
    "df_obesity['Disease'] = 'obesity'\n",
    "df_asthma['Disease'] = 'asthma'\n",
    "df_schizophrenia['Disease'] = 'schizophrenia'\n",
    "df_hypertension['Disease'] = 'hypertension'\n",
    "\n",
    "df = pd.concat([df_obesity, df_asthma, df_schizophrenia, df_hypertension], axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Gene name</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEP</td>\n",
       "      <td>0.758912</td>\n",
       "      <td>obesity</td>\n",
       "      <td>LEP</td>\n",
       "      <td>This gene encodes a protein that is secreted b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THRSP</td>\n",
       "      <td>0.741904</td>\n",
       "      <td>obesity</td>\n",
       "      <td>THRSP</td>\n",
       "      <td>The protein encoded by this gene is similar to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAZF1</td>\n",
       "      <td>0.720466</td>\n",
       "      <td>obesity</td>\n",
       "      <td>JAZF1</td>\n",
       "      <td>Acts as a transcriptional corepressor of orph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1QTNF12</td>\n",
       "      <td>0.711311</td>\n",
       "      <td>obesity</td>\n",
       "      <td>C1QTNF12</td>\n",
       "      <td>Predicted to enable hormone activity. Predicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEPROT</td>\n",
       "      <td>0.708792</td>\n",
       "      <td>obesity</td>\n",
       "      <td>LEPROT</td>\n",
       "      <td>LEPROT is associated with the Golgi complex an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>TRPC3</td>\n",
       "      <td>0.560457</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>TRPC3</td>\n",
       "      <td>The protein encoded by this gene is a membrane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GPR182</td>\n",
       "      <td>0.560197</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>GPR182</td>\n",
       "      <td>Adrenomedullin is a potent vasodilator peptide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>0.558525</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Potassium channels play a role in many cellula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>CD36</td>\n",
       "      <td>0.558066</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>CD36</td>\n",
       "      <td>The protein encoded by this gene is the fourth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>PRKCE</td>\n",
       "      <td>0.558050</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>PRKCE</td>\n",
       "      <td>alciumindependent, phospholipid and diacylgly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene  Cosine Similarity       Disease Gene name  \\\n",
       "0         LEP           0.758912       obesity       LEP   \n",
       "1       THRSP           0.741904       obesity     THRSP   \n",
       "2       JAZF1           0.720466       obesity     JAZF1   \n",
       "3    C1QTNF12           0.711311       obesity  C1QTNF12   \n",
       "4      LEPROT           0.708792       obesity    LEPROT   \n",
       "..        ...                ...           ...       ...   \n",
       "395     TRPC3           0.560457  hypertension     TRPC3   \n",
       "396    GPR182           0.560197  hypertension    GPR182   \n",
       "397    KCNK18           0.558525  hypertension    KCNK18   \n",
       "398      CD36           0.558066  hypertension      CD36   \n",
       "399     PRKCE           0.558050  hypertension     PRKCE   \n",
       "\n",
       "                                               Summary  \n",
       "0    This gene encodes a protein that is secreted b...  \n",
       "1    The protein encoded by this gene is similar to...  \n",
       "2     Acts as a transcriptional corepressor of orph...  \n",
       "3    Predicted to enable hormone activity. Predicte...  \n",
       "4    LEPROT is associated with the Golgi complex an...  \n",
       "..                                                 ...  \n",
       "395  The protein encoded by this gene is a membrane...  \n",
       "396  Adrenomedullin is a potent vasodilator peptide...  \n",
       "397  Potassium channels play a role in many cellula...  \n",
       "398  The protein encoded by this gene is the fourth...  \n",
       "399   alciumindependent, phospholipid and diacylgly...  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a pretrained model from a state dictionary ...\n",
      "Tokenization ...\n",
      "Tokenization Done.\n",
      "Get Embeddings ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 72.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([395, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEP</td>\n",
       "      <td>0.401820</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.138294</td>\n",
       "      <td>0.064681</td>\n",
       "      <td>-0.121166</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.193633</td>\n",
       "      <td>0.331752</td>\n",
       "      <td>0.811940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732070</td>\n",
       "      <td>0.192608</td>\n",
       "      <td>-0.063601</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.088668</td>\n",
       "      <td>0.084305</td>\n",
       "      <td>0.073466</td>\n",
       "      <td>-0.386494</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>0.503482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THRSP</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.633899</td>\n",
       "      <td>-0.172188</td>\n",
       "      <td>0.674709</td>\n",
       "      <td>-0.197604</td>\n",
       "      <td>0.549218</td>\n",
       "      <td>0.074492</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>0.798039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511492</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>-0.223601</td>\n",
       "      <td>-0.159075</td>\n",
       "      <td>-0.110663</td>\n",
       "      <td>0.207832</td>\n",
       "      <td>-0.225697</td>\n",
       "      <td>-0.693335</td>\n",
       "      <td>0.079949</td>\n",
       "      <td>0.099870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAZF1</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>0.966914</td>\n",
       "      <td>0.071201</td>\n",
       "      <td>0.498121</td>\n",
       "      <td>-0.086072</td>\n",
       "      <td>0.286590</td>\n",
       "      <td>-0.025821</td>\n",
       "      <td>0.413296</td>\n",
       "      <td>1.255126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805195</td>\n",
       "      <td>0.045931</td>\n",
       "      <td>-0.176672</td>\n",
       "      <td>-0.204219</td>\n",
       "      <td>-0.303561</td>\n",
       "      <td>0.253543</td>\n",
       "      <td>-0.412748</td>\n",
       "      <td>-0.677840</td>\n",
       "      <td>0.167411</td>\n",
       "      <td>0.162782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1QTNF12</td>\n",
       "      <td>0.271985</td>\n",
       "      <td>0.343538</td>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.301222</td>\n",
       "      <td>0.076676</td>\n",
       "      <td>0.309229</td>\n",
       "      <td>1.288095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966583</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>-0.166362</td>\n",
       "      <td>-0.227300</td>\n",
       "      <td>-0.174461</td>\n",
       "      <td>0.367383</td>\n",
       "      <td>-0.178256</td>\n",
       "      <td>-0.759278</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>0.497670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEPROT</td>\n",
       "      <td>0.453366</td>\n",
       "      <td>0.293181</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.342967</td>\n",
       "      <td>0.594061</td>\n",
       "      <td>-0.077142</td>\n",
       "      <td>0.312388</td>\n",
       "      <td>-0.207635</td>\n",
       "      <td>0.787018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800582</td>\n",
       "      <td>-0.149457</td>\n",
       "      <td>0.062632</td>\n",
       "      <td>0.167698</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>0.341324</td>\n",
       "      <td>0.098344</td>\n",
       "      <td>-0.614071</td>\n",
       "      <td>-0.015764</td>\n",
       "      <td>0.314205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>TRPC3</td>\n",
       "      <td>-0.279923</td>\n",
       "      <td>-0.540060</td>\n",
       "      <td>-0.319850</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>-0.680006</td>\n",
       "      <td>-0.231466</td>\n",
       "      <td>0.120466</td>\n",
       "      <td>0.662462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209290</td>\n",
       "      <td>-0.043997</td>\n",
       "      <td>0.445040</td>\n",
       "      <td>0.152601</td>\n",
       "      <td>0.232559</td>\n",
       "      <td>-0.050196</td>\n",
       "      <td>0.578297</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>0.096527</td>\n",
       "      <td>0.375377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>GPR182</td>\n",
       "      <td>-0.062727</td>\n",
       "      <td>-0.056829</td>\n",
       "      <td>0.341810</td>\n",
       "      <td>-0.242273</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>-0.085437</td>\n",
       "      <td>0.738598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210477</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>-0.331619</td>\n",
       "      <td>-0.164482</td>\n",
       "      <td>-0.029032</td>\n",
       "      <td>-0.335184</td>\n",
       "      <td>-0.015981</td>\n",
       "      <td>-0.456751</td>\n",
       "      <td>0.284081</td>\n",
       "      <td>0.057050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>0.631262</td>\n",
       "      <td>-0.484671</td>\n",
       "      <td>-0.535359</td>\n",
       "      <td>0.339540</td>\n",
       "      <td>0.364236</td>\n",
       "      <td>-0.858806</td>\n",
       "      <td>0.043966</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>0.219604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>-0.376143</td>\n",
       "      <td>0.835560</td>\n",
       "      <td>0.205990</td>\n",
       "      <td>0.275130</td>\n",
       "      <td>-0.097203</td>\n",
       "      <td>0.798008</td>\n",
       "      <td>-0.437516</td>\n",
       "      <td>0.387648</td>\n",
       "      <td>0.728651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>CD36</td>\n",
       "      <td>0.517931</td>\n",
       "      <td>0.427913</td>\n",
       "      <td>-0.437248</td>\n",
       "      <td>-0.078829</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>0.164973</td>\n",
       "      <td>0.246903</td>\n",
       "      <td>0.603171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172504</td>\n",
       "      <td>0.283440</td>\n",
       "      <td>-0.299242</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>-0.230992</td>\n",
       "      <td>-0.114485</td>\n",
       "      <td>-0.222148</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.415916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>PRKCE</td>\n",
       "      <td>-0.074059</td>\n",
       "      <td>-0.144695</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>-0.130187</td>\n",
       "      <td>-0.133956</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>0.553455</td>\n",
       "      <td>0.403792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>-0.093818</td>\n",
       "      <td>0.237890</td>\n",
       "      <td>0.587359</td>\n",
       "      <td>0.290850</td>\n",
       "      <td>-0.344318</td>\n",
       "      <td>0.038670</td>\n",
       "      <td>-0.234526</td>\n",
       "      <td>0.181492</td>\n",
       "      <td>-0.008361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gene name         0         1         2         3         4         5  \\\n",
       "0         LEP  0.401820  0.373210  0.138294  0.064681 -0.121166  0.039754   \n",
       "1       THRSP  0.233719  0.633899 -0.172188  0.674709 -0.197604  0.549218   \n",
       "2       JAZF1  0.092980  0.966914  0.071201  0.498121 -0.086072  0.286590   \n",
       "3    C1QTNF12  0.271985  0.343538  0.124735  0.357906  0.040200  0.301222   \n",
       "4      LEPROT  0.453366  0.293181  0.210744  0.342967  0.594061 -0.077142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "390     TRPC3 -0.279923 -0.540060 -0.319850  0.274256  0.073394 -0.680006   \n",
       "391    GPR182 -0.062727 -0.056829  0.341810 -0.242273  0.103200  0.044457   \n",
       "392    KCNK18  0.631262 -0.484671 -0.535359  0.339540  0.364236 -0.858806   \n",
       "393      CD36  0.517931  0.427913 -0.437248 -0.078829  0.301689  0.215548   \n",
       "394     PRKCE -0.074059 -0.144695  0.095028 -0.130187 -0.133956  0.015448   \n",
       "\n",
       "            6         7         8  ...       758       759       760  \\\n",
       "0    0.193633  0.331752  0.811940  ... -0.732070  0.192608 -0.063601   \n",
       "1    0.074492 -0.007133  0.798039  ... -0.511492  0.181888 -0.223601   \n",
       "2   -0.025821  0.413296  1.255126  ... -0.805195  0.045931 -0.176672   \n",
       "3    0.076676  0.309229  1.288095  ... -0.966583  0.094286 -0.166362   \n",
       "4    0.312388 -0.207635  0.787018  ... -0.800582 -0.149457  0.062632   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "390 -0.231466  0.120466  0.662462  ... -0.209290 -0.043997  0.445040   \n",
       "391  0.217844 -0.085437  0.738598  ... -0.210477  0.065162 -0.331619   \n",
       "392  0.043966  0.367130  0.219604  ...  0.088608 -0.376143  0.835560   \n",
       "393  0.164973  0.246903  0.603171  ... -0.172504  0.283440 -0.299242   \n",
       "394 -0.126036  0.553455  0.403792  ...  0.018422 -0.093818  0.237890   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0    0.002144 -0.088668  0.084305  0.073466 -0.386494 -0.024886  0.503482  \n",
       "1   -0.159075 -0.110663  0.207832 -0.225697 -0.693335  0.079949  0.099870  \n",
       "2   -0.204219 -0.303561  0.253543 -0.412748 -0.677840  0.167411  0.162782  \n",
       "3   -0.227300 -0.174461  0.367383 -0.178256 -0.759278 -0.012383  0.497670  \n",
       "4    0.167698  0.137014  0.341324  0.098344 -0.614071 -0.015764  0.314205  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "390  0.152601  0.232559 -0.050196  0.578297  0.077571  0.096527  0.375377  \n",
       "391 -0.164482 -0.029032 -0.335184 -0.015981 -0.456751  0.284081  0.057050  \n",
       "392  0.205990  0.275130 -0.097203  0.798008 -0.437516  0.387648  0.728651  \n",
       "393  0.018467  0.021558 -0.230992 -0.114485 -0.222148  0.064239  0.415916  \n",
       "394  0.587359  0.290850 -0.344318  0.038670 -0.234526  0.181492 -0.008361  \n",
       "\n",
       "[395 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def predict_pathway(df_relation):\n",
    "    # Assuming the file path and column names are correct\n",
    "    genes = pd.read_csv(\"/data/macaulay/GeneLLM2/data/clean_genes.csv\")\n",
    "    all_genes = genes[\"Gene name\"].to_list()\n",
    "    print(\"1\")\n",
    "    \n",
    "    # Merge based on 'Gene' column from df_relation and 'Gene name' from genes\n",
    "    df_merge = pd.merge(df_relation, genes, left_on='Gene', right_on='Gene name', how='left')\n",
    "    display(df_merge)\n",
    "\n",
    "    # Filter out rows without a summary\n",
    "    df_merge = df_merge.dropna(subset=['Summary'])\n",
    "    gene_to_summary = df_merge.set_index('Gene name')['Summary'].to_dict()\n",
    "\n",
    "    gene_names = list(gene_to_summary.keys())\n",
    "    gene_text = list(gene_to_summary.values())\n",
    "    \n",
    "    # Load your model and get embeddings\n",
    "    loaded_model = torch.load(\"state_dict_0.pth\")\n",
    "    embed = getEmbeddings(gene_text, loaded_model, batch_size=2000).detach().cpu().numpy()\n",
    "    \n",
    "    # Create a DataFrame to map gene names to embeddings\n",
    "    embeddings_df = pd.DataFrame(embed, index=gene_names)\n",
    "    embeddings_df.reset_index(inplace=True)\n",
    "    embeddings_df.rename(columns={'index': 'Gene name'}, inplace=True)\n",
    "    \n",
    "    # Now, embeddings_df contains each gene name and its corresponding embedding\n",
    "    display(embeddings_df)\n",
    "    return embeddings_df\n",
    "\n",
    "    # Optional: Save the embeddings DataFrame to a CSV file\n",
    "    \n",
    "\n",
    "embeddings_df = predict_pathway(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Disease</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEP</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.401820</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.138294</td>\n",
       "      <td>0.064681</td>\n",
       "      <td>-0.121166</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.193633</td>\n",
       "      <td>0.331752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732070</td>\n",
       "      <td>0.192608</td>\n",
       "      <td>-0.063601</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.088668</td>\n",
       "      <td>0.084305</td>\n",
       "      <td>0.073466</td>\n",
       "      <td>-0.386494</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>0.503482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THRSP</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.633899</td>\n",
       "      <td>-0.172188</td>\n",
       "      <td>0.674709</td>\n",
       "      <td>-0.197604</td>\n",
       "      <td>0.549218</td>\n",
       "      <td>0.074492</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511492</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>-0.223601</td>\n",
       "      <td>-0.159075</td>\n",
       "      <td>-0.110663</td>\n",
       "      <td>0.207832</td>\n",
       "      <td>-0.225697</td>\n",
       "      <td>-0.693335</td>\n",
       "      <td>0.079949</td>\n",
       "      <td>0.099870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAZF1</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>0.966914</td>\n",
       "      <td>0.071201</td>\n",
       "      <td>0.498121</td>\n",
       "      <td>-0.086072</td>\n",
       "      <td>0.286590</td>\n",
       "      <td>-0.025821</td>\n",
       "      <td>0.413296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805195</td>\n",
       "      <td>0.045931</td>\n",
       "      <td>-0.176672</td>\n",
       "      <td>-0.204219</td>\n",
       "      <td>-0.303561</td>\n",
       "      <td>0.253543</td>\n",
       "      <td>-0.412748</td>\n",
       "      <td>-0.677840</td>\n",
       "      <td>0.167411</td>\n",
       "      <td>0.162782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1QTNF12</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.271985</td>\n",
       "      <td>0.343538</td>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.301222</td>\n",
       "      <td>0.076676</td>\n",
       "      <td>0.309229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966583</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>-0.166362</td>\n",
       "      <td>-0.227300</td>\n",
       "      <td>-0.174461</td>\n",
       "      <td>0.367383</td>\n",
       "      <td>-0.178256</td>\n",
       "      <td>-0.759278</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>0.497670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEPROT</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.453366</td>\n",
       "      <td>0.293181</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.342967</td>\n",
       "      <td>0.594061</td>\n",
       "      <td>-0.077142</td>\n",
       "      <td>0.312388</td>\n",
       "      <td>-0.207635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800582</td>\n",
       "      <td>-0.149457</td>\n",
       "      <td>0.062632</td>\n",
       "      <td>0.167698</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>0.341324</td>\n",
       "      <td>0.098344</td>\n",
       "      <td>-0.614071</td>\n",
       "      <td>-0.015764</td>\n",
       "      <td>0.314205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>TRPC3</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>-0.279923</td>\n",
       "      <td>-0.540060</td>\n",
       "      <td>-0.319850</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>-0.680006</td>\n",
       "      <td>-0.231466</td>\n",
       "      <td>0.120466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209290</td>\n",
       "      <td>-0.043997</td>\n",
       "      <td>0.445040</td>\n",
       "      <td>0.152601</td>\n",
       "      <td>0.232559</td>\n",
       "      <td>-0.050196</td>\n",
       "      <td>0.578297</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>0.096527</td>\n",
       "      <td>0.375377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GPR182</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>-0.062727</td>\n",
       "      <td>-0.056829</td>\n",
       "      <td>0.341810</td>\n",
       "      <td>-0.242273</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>-0.085437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210477</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>-0.331619</td>\n",
       "      <td>-0.164482</td>\n",
       "      <td>-0.029032</td>\n",
       "      <td>-0.335184</td>\n",
       "      <td>-0.015981</td>\n",
       "      <td>-0.456751</td>\n",
       "      <td>0.284081</td>\n",
       "      <td>0.057050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.631262</td>\n",
       "      <td>-0.484671</td>\n",
       "      <td>-0.535359</td>\n",
       "      <td>0.339540</td>\n",
       "      <td>0.364236</td>\n",
       "      <td>-0.858806</td>\n",
       "      <td>0.043966</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>-0.376143</td>\n",
       "      <td>0.835560</td>\n",
       "      <td>0.205990</td>\n",
       "      <td>0.275130</td>\n",
       "      <td>-0.097203</td>\n",
       "      <td>0.798008</td>\n",
       "      <td>-0.437516</td>\n",
       "      <td>0.387648</td>\n",
       "      <td>0.728651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>CD36</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.517931</td>\n",
       "      <td>0.427913</td>\n",
       "      <td>-0.437248</td>\n",
       "      <td>-0.078829</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>0.164973</td>\n",
       "      <td>0.246903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172504</td>\n",
       "      <td>0.283440</td>\n",
       "      <td>-0.299242</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>-0.230992</td>\n",
       "      <td>-0.114485</td>\n",
       "      <td>-0.222148</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.415916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>PRKCE</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>-0.074059</td>\n",
       "      <td>-0.144695</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>-0.130187</td>\n",
       "      <td>-0.133956</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>0.553455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>-0.093818</td>\n",
       "      <td>0.237890</td>\n",
       "      <td>0.587359</td>\n",
       "      <td>0.290850</td>\n",
       "      <td>-0.344318</td>\n",
       "      <td>0.038670</td>\n",
       "      <td>-0.234526</td>\n",
       "      <td>0.181492</td>\n",
       "      <td>-0.008361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene       Disease         0         1         2         3         4  \\\n",
       "0         LEP       obesity  0.401820  0.373210  0.138294  0.064681 -0.121166   \n",
       "1       THRSP       obesity  0.233719  0.633899 -0.172188  0.674709 -0.197604   \n",
       "2       JAZF1       obesity  0.092980  0.966914  0.071201  0.498121 -0.086072   \n",
       "3    C1QTNF12       obesity  0.271985  0.343538  0.124735  0.357906  0.040200   \n",
       "4      LEPROT       obesity  0.453366  0.293181  0.210744  0.342967  0.594061   \n",
       "..        ...           ...       ...       ...       ...       ...       ...   \n",
       "395     TRPC3  hypertension -0.279923 -0.540060 -0.319850  0.274256  0.073394   \n",
       "396    GPR182  hypertension -0.062727 -0.056829  0.341810 -0.242273  0.103200   \n",
       "397    KCNK18  hypertension  0.631262 -0.484671 -0.535359  0.339540  0.364236   \n",
       "398      CD36  hypertension  0.517931  0.427913 -0.437248 -0.078829  0.301689   \n",
       "399     PRKCE  hypertension -0.074059 -0.144695  0.095028 -0.130187 -0.133956   \n",
       "\n",
       "            5         6         7  ...       758       759       760  \\\n",
       "0    0.039754  0.193633  0.331752  ... -0.732070  0.192608 -0.063601   \n",
       "1    0.549218  0.074492 -0.007133  ... -0.511492  0.181888 -0.223601   \n",
       "2    0.286590 -0.025821  0.413296  ... -0.805195  0.045931 -0.176672   \n",
       "3    0.301222  0.076676  0.309229  ... -0.966583  0.094286 -0.166362   \n",
       "4   -0.077142  0.312388 -0.207635  ... -0.800582 -0.149457  0.062632   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395 -0.680006 -0.231466  0.120466  ... -0.209290 -0.043997  0.445040   \n",
       "396  0.044457  0.217844 -0.085437  ... -0.210477  0.065162 -0.331619   \n",
       "397 -0.858806  0.043966  0.367130  ...  0.088608 -0.376143  0.835560   \n",
       "398  0.215548  0.164973  0.246903  ... -0.172504  0.283440 -0.299242   \n",
       "399  0.015448 -0.126036  0.553455  ...  0.018422 -0.093818  0.237890   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0    0.002144 -0.088668  0.084305  0.073466 -0.386494 -0.024886  0.503482  \n",
       "1   -0.159075 -0.110663  0.207832 -0.225697 -0.693335  0.079949  0.099870  \n",
       "2   -0.204219 -0.303561  0.253543 -0.412748 -0.677840  0.167411  0.162782  \n",
       "3   -0.227300 -0.174461  0.367383 -0.178256 -0.759278 -0.012383  0.497670  \n",
       "4    0.167698  0.137014  0.341324  0.098344 -0.614071 -0.015764  0.314205  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "395  0.152601  0.232559 -0.050196  0.578297  0.077571  0.096527  0.375377  \n",
       "396 -0.164482 -0.029032 -0.335184 -0.015981 -0.456751  0.284081  0.057050  \n",
       "397  0.205990  0.275130 -0.097203  0.798008 -0.437516  0.387648  0.728651  \n",
       "398  0.018467  0.021558 -0.230992 -0.114485 -0.222148  0.064239  0.415916  \n",
       "399  0.587359  0.290850 -0.344318  0.038670 -0.234526  0.181492 -0.008361  \n",
       "\n",
       "[400 rows x 770 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(df, embeddings_df, left_on='Gene', right_on= 'Gene name', how='left')\n",
    "merged = merged.dropna(subset=[0])\n",
    "merged = merged.drop(columns=['Gene name', 'Cosine Similarity'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Disease</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEP</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.401820</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.138294</td>\n",
       "      <td>0.064681</td>\n",
       "      <td>-0.121166</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.193633</td>\n",
       "      <td>0.331752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732070</td>\n",
       "      <td>0.192608</td>\n",
       "      <td>-0.063601</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.088668</td>\n",
       "      <td>0.084305</td>\n",
       "      <td>0.073466</td>\n",
       "      <td>-0.386494</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>0.503482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THRSP</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.633899</td>\n",
       "      <td>-0.172188</td>\n",
       "      <td>0.674709</td>\n",
       "      <td>-0.197604</td>\n",
       "      <td>0.549218</td>\n",
       "      <td>0.074492</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511492</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>-0.223601</td>\n",
       "      <td>-0.159075</td>\n",
       "      <td>-0.110663</td>\n",
       "      <td>0.207832</td>\n",
       "      <td>-0.225697</td>\n",
       "      <td>-0.693335</td>\n",
       "      <td>0.079949</td>\n",
       "      <td>0.099870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAZF1</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>0.966914</td>\n",
       "      <td>0.071201</td>\n",
       "      <td>0.498121</td>\n",
       "      <td>-0.086072</td>\n",
       "      <td>0.286590</td>\n",
       "      <td>-0.025821</td>\n",
       "      <td>0.413296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805195</td>\n",
       "      <td>0.045931</td>\n",
       "      <td>-0.176672</td>\n",
       "      <td>-0.204219</td>\n",
       "      <td>-0.303561</td>\n",
       "      <td>0.253543</td>\n",
       "      <td>-0.412748</td>\n",
       "      <td>-0.677840</td>\n",
       "      <td>0.167411</td>\n",
       "      <td>0.162782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1QTNF12</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.271985</td>\n",
       "      <td>0.343538</td>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.301222</td>\n",
       "      <td>0.076676</td>\n",
       "      <td>0.309229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966583</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>-0.166362</td>\n",
       "      <td>-0.227300</td>\n",
       "      <td>-0.174461</td>\n",
       "      <td>0.367383</td>\n",
       "      <td>-0.178256</td>\n",
       "      <td>-0.759278</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>0.497670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEPROT</td>\n",
       "      <td>obesity</td>\n",
       "      <td>0.453366</td>\n",
       "      <td>0.293181</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.342967</td>\n",
       "      <td>0.594061</td>\n",
       "      <td>-0.077142</td>\n",
       "      <td>0.312388</td>\n",
       "      <td>-0.207635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800582</td>\n",
       "      <td>-0.149457</td>\n",
       "      <td>0.062632</td>\n",
       "      <td>0.167698</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>0.341324</td>\n",
       "      <td>0.098344</td>\n",
       "      <td>-0.614071</td>\n",
       "      <td>-0.015764</td>\n",
       "      <td>0.314205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>TRPC3</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>-0.279923</td>\n",
       "      <td>-0.540060</td>\n",
       "      <td>-0.319850</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>-0.680006</td>\n",
       "      <td>-0.231466</td>\n",
       "      <td>0.120466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209290</td>\n",
       "      <td>-0.043997</td>\n",
       "      <td>0.445040</td>\n",
       "      <td>0.152601</td>\n",
       "      <td>0.232559</td>\n",
       "      <td>-0.050196</td>\n",
       "      <td>0.578297</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>0.096527</td>\n",
       "      <td>0.375377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>GPR182</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>-0.062727</td>\n",
       "      <td>-0.056829</td>\n",
       "      <td>0.341810</td>\n",
       "      <td>-0.242273</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>-0.085437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210477</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>-0.331619</td>\n",
       "      <td>-0.164482</td>\n",
       "      <td>-0.029032</td>\n",
       "      <td>-0.335184</td>\n",
       "      <td>-0.015981</td>\n",
       "      <td>-0.456751</td>\n",
       "      <td>0.284081</td>\n",
       "      <td>0.057050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.631262</td>\n",
       "      <td>-0.484671</td>\n",
       "      <td>-0.535359</td>\n",
       "      <td>0.339540</td>\n",
       "      <td>0.364236</td>\n",
       "      <td>-0.858806</td>\n",
       "      <td>0.043966</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>-0.376143</td>\n",
       "      <td>0.835560</td>\n",
       "      <td>0.205990</td>\n",
       "      <td>0.275130</td>\n",
       "      <td>-0.097203</td>\n",
       "      <td>0.798008</td>\n",
       "      <td>-0.437516</td>\n",
       "      <td>0.387648</td>\n",
       "      <td>0.728651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>CD36</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.517931</td>\n",
       "      <td>0.427913</td>\n",
       "      <td>-0.437248</td>\n",
       "      <td>-0.078829</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>0.164973</td>\n",
       "      <td>0.246903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172504</td>\n",
       "      <td>0.283440</td>\n",
       "      <td>-0.299242</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>-0.230992</td>\n",
       "      <td>-0.114485</td>\n",
       "      <td>-0.222148</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.415916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>PRKCE</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>-0.074059</td>\n",
       "      <td>-0.144695</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>-0.130187</td>\n",
       "      <td>-0.133956</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>0.553455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>-0.093818</td>\n",
       "      <td>0.237890</td>\n",
       "      <td>0.587359</td>\n",
       "      <td>0.290850</td>\n",
       "      <td>-0.344318</td>\n",
       "      <td>0.038670</td>\n",
       "      <td>-0.234526</td>\n",
       "      <td>0.181492</td>\n",
       "      <td>-0.008361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene       Disease         0         1         2         3         4  \\\n",
       "0         LEP       obesity  0.401820  0.373210  0.138294  0.064681 -0.121166   \n",
       "1       THRSP       obesity  0.233719  0.633899 -0.172188  0.674709 -0.197604   \n",
       "2       JAZF1       obesity  0.092980  0.966914  0.071201  0.498121 -0.086072   \n",
       "3    C1QTNF12       obesity  0.271985  0.343538  0.124735  0.357906  0.040200   \n",
       "4      LEPROT       obesity  0.453366  0.293181  0.210744  0.342967  0.594061   \n",
       "..        ...           ...       ...       ...       ...       ...       ...   \n",
       "389     TRPC3  hypertension -0.279923 -0.540060 -0.319850  0.274256  0.073394   \n",
       "390    GPR182  hypertension -0.062727 -0.056829  0.341810 -0.242273  0.103200   \n",
       "391    KCNK18  hypertension  0.631262 -0.484671 -0.535359  0.339540  0.364236   \n",
       "392      CD36  hypertension  0.517931  0.427913 -0.437248 -0.078829  0.301689   \n",
       "393     PRKCE  hypertension -0.074059 -0.144695  0.095028 -0.130187 -0.133956   \n",
       "\n",
       "            5         6         7  ...       758       759       760  \\\n",
       "0    0.039754  0.193633  0.331752  ... -0.732070  0.192608 -0.063601   \n",
       "1    0.549218  0.074492 -0.007133  ... -0.511492  0.181888 -0.223601   \n",
       "2    0.286590 -0.025821  0.413296  ... -0.805195  0.045931 -0.176672   \n",
       "3    0.301222  0.076676  0.309229  ... -0.966583  0.094286 -0.166362   \n",
       "4   -0.077142  0.312388 -0.207635  ... -0.800582 -0.149457  0.062632   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "389 -0.680006 -0.231466  0.120466  ... -0.209290 -0.043997  0.445040   \n",
       "390  0.044457  0.217844 -0.085437  ... -0.210477  0.065162 -0.331619   \n",
       "391 -0.858806  0.043966  0.367130  ...  0.088608 -0.376143  0.835560   \n",
       "392  0.215548  0.164973  0.246903  ... -0.172504  0.283440 -0.299242   \n",
       "393  0.015448 -0.126036  0.553455  ...  0.018422 -0.093818  0.237890   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0    0.002144 -0.088668  0.084305  0.073466 -0.386494 -0.024886  0.503482  \n",
       "1   -0.159075 -0.110663  0.207832 -0.225697 -0.693335  0.079949  0.099870  \n",
       "2   -0.204219 -0.303561  0.253543 -0.412748 -0.677840  0.167411  0.162782  \n",
       "3   -0.227300 -0.174461  0.367383 -0.178256 -0.759278 -0.012383  0.497670  \n",
       "4    0.167698  0.137014  0.341324  0.098344 -0.614071 -0.015764  0.314205  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "389  0.152601  0.232559 -0.050196  0.578297  0.077571  0.096527  0.375377  \n",
       "390 -0.164482 -0.029032 -0.335184 -0.015981 -0.456751  0.284081  0.057050  \n",
       "391  0.205990  0.275130 -0.097203  0.798008 -0.437516  0.387648  0.728651  \n",
       "392  0.018467  0.021558 -0.230992 -0.114485 -0.222148  0.064239  0.415916  \n",
       "393  0.587359  0.290850 -0.344318  0.038670 -0.234526  0.181492 -0.008361  \n",
       "\n",
       "[394 rows x 770 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged\n",
    "df.drop_duplicates(subset=[0], inplace=True)\n",
    "gene_solubility = df.iloc[:, :2]  # This holds the gene name and solubility\n",
    "embeddings = df.iloc[:, 2:]\n",
    "  # This holds the embeddings\n",
    "\n",
    "# Step 4: Remove Duplicate Embeddings\n",
    "# Dropping duplicate embeddings and keeping the first occurrence\n",
    "unique_embeddings = embeddings.drop_duplicates()\n",
    "\n",
    "# Step 5: Rejoin Data\n",
    "# Since we want to join it back with the corresponding gene names and solubility,\n",
    "# we need to find the indices of the rows in the original dataframe that match the unique embeddings.\n",
    "# Then use these indices to extract the corresponding gene names and solubility.\n",
    "unique_indices = unique_embeddings.index\n",
    "unique_gene_solubility = gene_solubility.loc[unique_indices]\n",
    "\n",
    "# Now, combine the gene names/solubility with the unique embeddings\n",
    "final_df = pd.concat([unique_gene_solubility.reset_index(drop=True), unique_embeddings.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "final_df.to_csv(\"/data/macaulay/GeneLLM2/data/obesity_disease_gene_embeddings.csv\", index=False)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH:D001249\n",
    "MESH:D006973\n",
    "MESH:D009765\n",
    "MESH:D012559\n",
    "\n",
    "df_obesity['Disease'] = 'obesity'\n",
    "df_asthma['Disease'] = 'asthma'\n",
    "df_schizophrenia['Disease'] = 'schizophrenia'\n",
    "df_hypertension['Disease'] = 'hypertension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DO Disease Name</th>\n",
       "      <th>id</th>\n",
       "      <th>did</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>MESH:D006973</td>\n",
       "      <td>DOID:10763</td>\n",
       "      <td>An artery disease characterized by chronic ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>asthma</td>\n",
       "      <td>MESH:D001249</td>\n",
       "      <td>DOID:2841</td>\n",
       "      <td>A bronchial disease that is characterized by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>MESH:D012559</td>\n",
       "      <td>DOID:5419</td>\n",
       "      <td>A psychotic disorder that is characterized by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>obesity</td>\n",
       "      <td>MESH:D009765</td>\n",
       "      <td>DOID:9970</td>\n",
       "      <td>An overnutrition that is characterized by exce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DO Disease Name            id         did  \\\n",
       "1041    hypertension  MESH:D006973  DOID:10763   \n",
       "1479          asthma  MESH:D001249   DOID:2841   \n",
       "1723   schizophrenia  MESH:D012559   DOID:5419   \n",
       "1939         obesity  MESH:D009765   DOID:9970   \n",
       "\n",
       "                                                summary  \n",
       "1041  An artery disease characterized by chronic ele...  \n",
       "1479  A bronchial disease that is characterized by c...  \n",
       "1723  A psychotic disorder that is characterized by ...  \n",
       "1939  An overnutrition that is characterized by exce...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_mgi = pd.read_csv('disease_summary_MGI2.txt', sep='\\t', header=None)\n",
    "df_mgi.columns = ['DO Disease Name', 'id', 'did','summary']\n",
    "df_mgi = df_mgi.dropna().reset_index(drop=True)\n",
    "# df_mgi\n",
    "# asthma_rows = df_mgi[df_mgi['DO Disease Name'].str.contains(\"schizophrenia\", case=False)]\n",
    "\n",
    "# # Display the filtered rows\n",
    "# asthma_rows\n",
    "\n",
    "mesh_ids = ['MESH:D001249', 'MESH:D006973', 'MESH:D009765', 'MESH:D012559']\n",
    "\n",
    "# Filter df_mgi to keep rows where the 'id' column matches any of the MESH IDs in the list\n",
    "df = df_mgi[df_mgi['id'].isin(mesh_ids)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hypertension', 'asthma', 'schizophrenia', 'obesity']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diseas_list = df['summary'].to_list()\n",
    "diseas_name = df['DO Disease Name'].to_list()\n",
    "diseas_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a pretrained model from a state dictionary ...\n",
      "Tokenization ...\n",
      "Tokenization Done.\n",
      "Get Embeddings ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 89.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.708679</td>\n",
       "      <td>0.435822</td>\n",
       "      <td>-0.507633</td>\n",
       "      <td>0.396858</td>\n",
       "      <td>-0.458109</td>\n",
       "      <td>-0.739938</td>\n",
       "      <td>0.288066</td>\n",
       "      <td>0.296280</td>\n",
       "      <td>0.622939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.167867</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>-0.409624</td>\n",
       "      <td>-0.275540</td>\n",
       "      <td>0.312540</td>\n",
       "      <td>-0.274273</td>\n",
       "      <td>-0.483903</td>\n",
       "      <td>0.965353</td>\n",
       "      <td>0.040116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asthma</td>\n",
       "      <td>0.910803</td>\n",
       "      <td>0.233318</td>\n",
       "      <td>-0.274740</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>0.483768</td>\n",
       "      <td>0.692197</td>\n",
       "      <td>0.567663</td>\n",
       "      <td>0.574138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198966</td>\n",
       "      <td>0.699910</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>0.424925</td>\n",
       "      <td>0.174062</td>\n",
       "      <td>-0.094743</td>\n",
       "      <td>0.419234</td>\n",
       "      <td>0.248716</td>\n",
       "      <td>1.413107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>0.361688</td>\n",
       "      <td>0.748994</td>\n",
       "      <td>-0.423147</td>\n",
       "      <td>0.599872</td>\n",
       "      <td>-0.297578</td>\n",
       "      <td>0.061553</td>\n",
       "      <td>-0.588028</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449921</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.524088</td>\n",
       "      <td>-0.710619</td>\n",
       "      <td>-0.053389</td>\n",
       "      <td>0.068494</td>\n",
       "      <td>0.714823</td>\n",
       "      <td>0.128198</td>\n",
       "      <td>0.710103</td>\n",
       "      <td>0.513897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obesity</td>\n",
       "      <td>0.421315</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.185262</td>\n",
       "      <td>-0.039173</td>\n",
       "      <td>0.353730</td>\n",
       "      <td>0.337592</td>\n",
       "      <td>0.101680</td>\n",
       "      <td>-0.259099</td>\n",
       "      <td>0.380311</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.013368</td>\n",
       "      <td>0.303655</td>\n",
       "      <td>-0.180275</td>\n",
       "      <td>0.215209</td>\n",
       "      <td>-0.780538</td>\n",
       "      <td>0.356815</td>\n",
       "      <td>-0.196825</td>\n",
       "      <td>-0.991935</td>\n",
       "      <td>0.548198</td>\n",
       "      <td>0.831418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Disease name         0         1         2         3         4         5  \\\n",
       "0   hypertension  0.708679  0.435822 -0.507633  0.396858 -0.458109 -0.739938   \n",
       "1         asthma  0.910803  0.233318 -0.274740  0.028964  0.055083  0.483768   \n",
       "2  schizophrenia  0.044523  0.361688  0.748994 -0.423147  0.599872 -0.297578   \n",
       "3        obesity  0.421315  0.004165  0.185262 -0.039173  0.353730  0.337592   \n",
       "\n",
       "          6         7         8  ...       758       759       760       761  \\\n",
       "0  0.288066  0.296280  0.622939  ...  0.007841  0.167867  0.024460 -0.409624   \n",
       "1  0.692197  0.567663  0.574138  ...  0.198966  0.699910  0.999969 -0.298612   \n",
       "2  0.061553 -0.588028  0.093129  ... -0.449921  0.010691  0.524088 -0.710619   \n",
       "3  0.101680 -0.259099  0.380311  ... -1.013368  0.303655 -0.180275  0.215209   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.275540  0.312540 -0.274273 -0.483903  0.965353  0.040116  \n",
       "1  0.424925  0.174062 -0.094743  0.419234  0.248716  1.413107  \n",
       "2 -0.053389  0.068494  0.714823  0.128198  0.710103  0.513897  \n",
       "3 -0.780538  0.356815 -0.196825 -0.991935  0.548198  0.831418  \n",
       "\n",
       "[4 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def predict_pathway(gene_names,  gene_text):\n",
    "   \n",
    "    # Load your model and get embeddings\n",
    "    loaded_model = torch.load(\"state_dict_0.pth\")\n",
    "    embed = getEmbeddings(gene_text, loaded_model, batch_size=2000).detach().cpu().numpy()\n",
    "    \n",
    "    # Create a DataFrame to map gene names to embeddings\n",
    "    embeddings_df = pd.DataFrame(embed, index=gene_names)\n",
    "    embeddings_df.reset_index(inplace=True)\n",
    "    embeddings_df.rename(columns={'index': 'Disease name'}, inplace=True)\n",
    "    \n",
    "    # Now, embeddings_df contains each gene name and its corresponding embedding\n",
    "    display(embeddings_df)\n",
    "    return embeddings_df\n",
    "\n",
    "    # Optional: Save the embeddings DataFrame to a CSV file\n",
    "    \n",
    "\n",
    "embeddings_df = predict_pathway(diseas_name, diseas_list)\n",
    "embeddings_df.to_csv(\"disease_embeddings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GO Term ID</th>\n",
       "      <th>Def Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>The distribution of mitochondria, including th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>The maintenance of the structure and integrity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000003</td>\n",
       "      <td>The production of new individuals that contain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000005</td>\n",
       "      <td>OBSOLETE. Assists in the correct assembly of r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>Enables the transfer of zinc ions (Zn2+) from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>GO:2001313</td>\n",
       "      <td>The chemical reactions and pathways involving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47591</th>\n",
       "      <td>GO:2001314</td>\n",
       "      <td>The chemical reactions and pathways resulting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47592</th>\n",
       "      <td>GO:2001315</td>\n",
       "      <td>The chemical reactions and pathways resulting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47593</th>\n",
       "      <td>GO:2001316</td>\n",
       "      <td>The chemical reactions and pathways involving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47594</th>\n",
       "      <td>GO:2001317</td>\n",
       "      <td>The chemical reactions and pathways resulting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GO Term ID                                        Def Summary\n",
       "0      GO:0000001  The distribution of mitochondria, including th...\n",
       "1      GO:0000002  The maintenance of the structure and integrity...\n",
       "2      GO:0000003  The production of new individuals that contain...\n",
       "3      GO:0000005  OBSOLETE. Assists in the correct assembly of r...\n",
       "4      GO:0000006  Enables the transfer of zinc ions (Zn2+) from ...\n",
       "...           ...                                                ...\n",
       "47590  GO:2001313  The chemical reactions and pathways involving ...\n",
       "47591  GO:2001314  The chemical reactions and pathways resulting ...\n",
       "47592  GO:2001315  The chemical reactions and pathways resulting ...\n",
       "47593  GO:2001316  The chemical reactions and pathways involving ...\n",
       "47594  GO:2001317  The chemical reactions and pathways resulting ...\n",
       "\n",
       "[47595 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('go_terms_summaary.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GO:0000001',\n",
       " 'GO:0000002',\n",
       " 'GO:0000003',\n",
       " 'GO:0000005',\n",
       " 'GO:0000006',\n",
       " 'GO:0000007',\n",
       " 'GO:0000008',\n",
       " 'GO:0000009',\n",
       " 'GO:0000010',\n",
       " 'GO:0000011',\n",
       " 'GO:0000012',\n",
       " 'GO:0000014',\n",
       " 'GO:0000015',\n",
       " 'GO:0000016',\n",
       " 'GO:0000017',\n",
       " 'GO:0000018',\n",
       " 'GO:0000019',\n",
       " 'GO:0000020',\n",
       " 'GO:0000022',\n",
       " 'GO:0000023',\n",
       " 'GO:0000024',\n",
       " 'GO:0000025',\n",
       " 'GO:0000026',\n",
       " 'GO:0000027',\n",
       " 'GO:0000028',\n",
       " 'GO:0000030',\n",
       " 'GO:0000031',\n",
       " 'GO:0000032',\n",
       " 'GO:0000033',\n",
       " 'GO:0000034',\n",
       " 'GO:0000035',\n",
       " 'GO:0000036',\n",
       " 'GO:0000038',\n",
       " 'GO:0000039',\n",
       " 'GO:0000041',\n",
       " 'GO:0000044',\n",
       " 'GO:0000045',\n",
       " 'GO:0000047',\n",
       " 'GO:0000048',\n",
       " 'GO:0000049',\n",
       " 'GO:0000050',\n",
       " 'GO:0000051',\n",
       " 'GO:0000052',\n",
       " 'GO:0000053',\n",
       " 'GO:0000054',\n",
       " 'GO:0000055',\n",
       " 'GO:0000056',\n",
       " 'GO:0000059',\n",
       " 'GO:0000060',\n",
       " 'GO:0000061',\n",
       " 'GO:0000062',\n",
       " 'GO:0000064',\n",
       " 'GO:0000067',\n",
       " 'GO:0000070',\n",
       " 'GO:0000072',\n",
       " 'GO:0000073',\n",
       " 'GO:0000075',\n",
       " 'GO:0000076',\n",
       " 'GO:0000077',\n",
       " 'GO:0000078',\n",
       " 'GO:0000079',\n",
       " 'GO:0000080',\n",
       " 'GO:0000082',\n",
       " 'GO:0000083',\n",
       " 'GO:0000084',\n",
       " 'GO:0000085',\n",
       " 'GO:0000086',\n",
       " 'GO:0000087',\n",
       " 'GO:0000088',\n",
       " 'GO:0000089',\n",
       " 'GO:0000090',\n",
       " 'GO:0000091',\n",
       " 'GO:0000092',\n",
       " 'GO:0000093',\n",
       " 'GO:0000094',\n",
       " 'GO:0000095',\n",
       " 'GO:0000096',\n",
       " 'GO:0000097',\n",
       " 'GO:0000098',\n",
       " 'GO:0000099',\n",
       " 'GO:0000100',\n",
       " 'GO:0000101',\n",
       " 'GO:0000102',\n",
       " 'GO:0000103',\n",
       " 'GO:0000104',\n",
       " 'GO:0000105',\n",
       " 'GO:0000107',\n",
       " 'GO:0000108',\n",
       " 'GO:0000109',\n",
       " 'GO:0000110',\n",
       " 'GO:0000111',\n",
       " 'GO:0000112',\n",
       " 'GO:0000113',\n",
       " 'GO:0000114',\n",
       " 'GO:0000115',\n",
       " 'GO:0000116',\n",
       " 'GO:0000117',\n",
       " 'GO:0000118',\n",
       " 'GO:0000120',\n",
       " 'GO:0000121',\n",
       " 'GO:0000122',\n",
       " 'GO:0000123',\n",
       " 'GO:0000124',\n",
       " 'GO:0000126',\n",
       " 'GO:0000127',\n",
       " 'GO:0000128',\n",
       " 'GO:0000131',\n",
       " 'GO:0000132',\n",
       " 'GO:0000133',\n",
       " 'GO:0000136',\n",
       " 'GO:0000137',\n",
       " 'GO:0000138',\n",
       " 'GO:0000139',\n",
       " 'GO:0000140',\n",
       " 'GO:0000142',\n",
       " 'GO:0000144',\n",
       " 'GO:0000145',\n",
       " 'GO:0000146',\n",
       " 'GO:0000147',\n",
       " 'GO:0000148',\n",
       " 'GO:0000149',\n",
       " 'GO:0000150',\n",
       " 'GO:0000151',\n",
       " 'GO:0000152',\n",
       " 'GO:0000153',\n",
       " 'GO:0000154',\n",
       " 'GO:0000155',\n",
       " 'GO:0000156',\n",
       " 'GO:0000159',\n",
       " 'GO:0000160',\n",
       " 'GO:0000161',\n",
       " 'GO:0000162',\n",
       " 'GO:0000164',\n",
       " 'GO:0000165',\n",
       " 'GO:0000166',\n",
       " 'GO:0000170',\n",
       " 'GO:0000171',\n",
       " 'GO:0000172',\n",
       " 'GO:0000174',\n",
       " 'GO:0000175',\n",
       " 'GO:0000176',\n",
       " 'GO:0000177',\n",
       " 'GO:0000178',\n",
       " 'GO:0000179',\n",
       " 'GO:0000180',\n",
       " 'GO:0000181',\n",
       " 'GO:0000182',\n",
       " 'GO:0000183',\n",
       " 'GO:0000184',\n",
       " 'GO:0000185',\n",
       " 'GO:0000186',\n",
       " 'GO:0000187',\n",
       " 'GO:0000188',\n",
       " 'GO:0000189',\n",
       " 'GO:0000190',\n",
       " 'GO:0000191',\n",
       " 'GO:0000192',\n",
       " 'GO:0000193',\n",
       " 'GO:0000194',\n",
       " 'GO:0000195',\n",
       " 'GO:0000196',\n",
       " 'GO:0000197',\n",
       " 'GO:0000198',\n",
       " 'GO:0000199',\n",
       " 'GO:0000200',\n",
       " 'GO:0000201',\n",
       " 'GO:0000202',\n",
       " 'GO:0000203',\n",
       " 'GO:0000204',\n",
       " 'GO:0000205',\n",
       " 'GO:0000206',\n",
       " 'GO:0000207',\n",
       " 'GO:0000208',\n",
       " 'GO:0000209',\n",
       " 'GO:0000210',\n",
       " 'GO:0000211',\n",
       " 'GO:0000212',\n",
       " 'GO:0000213',\n",
       " 'GO:0000214',\n",
       " 'GO:0000215',\n",
       " 'GO:0000216',\n",
       " 'GO:0000217',\n",
       " 'GO:0000219',\n",
       " 'GO:0000220',\n",
       " 'GO:0000221',\n",
       " 'GO:0000222',\n",
       " 'GO:0000223',\n",
       " 'GO:0000224',\n",
       " 'GO:0000225',\n",
       " 'GO:0000226',\n",
       " 'GO:0000227',\n",
       " 'GO:0000228',\n",
       " 'GO:0000229',\n",
       " 'GO:0000230',\n",
       " 'GO:0000231',\n",
       " 'GO:0000232',\n",
       " 'GO:0000233',\n",
       " 'GO:0000234',\n",
       " 'GO:0000235',\n",
       " 'GO:0000236',\n",
       " 'GO:0000237',\n",
       " 'GO:0000238',\n",
       " 'GO:0000239',\n",
       " 'GO:0000240',\n",
       " 'GO:0000241',\n",
       " 'GO:0000242',\n",
       " 'GO:0000243',\n",
       " 'GO:0000244',\n",
       " 'GO:0000245',\n",
       " 'GO:0000246',\n",
       " 'GO:0000247',\n",
       " 'GO:0000248',\n",
       " 'GO:0000249',\n",
       " 'GO:0000250',\n",
       " 'GO:0000252',\n",
       " 'GO:0000253',\n",
       " 'GO:0000254',\n",
       " 'GO:0000255',\n",
       " 'GO:0000256',\n",
       " 'GO:0000257',\n",
       " 'GO:0000258',\n",
       " 'GO:0000259',\n",
       " 'GO:0000260',\n",
       " 'GO:0000261',\n",
       " 'GO:0000262',\n",
       " 'GO:0000263',\n",
       " 'GO:0000264',\n",
       " 'GO:0000265',\n",
       " 'GO:0000266',\n",
       " 'GO:0000267',\n",
       " 'GO:0000268',\n",
       " 'GO:0000269',\n",
       " 'GO:0000270',\n",
       " 'GO:0000271',\n",
       " 'GO:0000272',\n",
       " 'GO:0000274',\n",
       " 'GO:0000275',\n",
       " 'GO:0000276',\n",
       " 'GO:0000277',\n",
       " 'GO:0000278',\n",
       " 'GO:0000279',\n",
       " 'GO:0000280',\n",
       " 'GO:0000281',\n",
       " 'GO:0000282',\n",
       " 'GO:0000284',\n",
       " 'GO:0000285',\n",
       " 'GO:0000286',\n",
       " 'GO:0000287',\n",
       " 'GO:0000288',\n",
       " 'GO:0000289',\n",
       " 'GO:0000290',\n",
       " 'GO:0000291',\n",
       " 'GO:0000292',\n",
       " 'GO:0000293',\n",
       " 'GO:0000294',\n",
       " 'GO:0000295',\n",
       " 'GO:0000296',\n",
       " 'GO:0000297',\n",
       " 'GO:0000298',\n",
       " 'GO:0000299',\n",
       " 'GO:0000300',\n",
       " 'GO:0000301',\n",
       " 'GO:0000302',\n",
       " 'GO:0000303',\n",
       " 'GO:0000304',\n",
       " 'GO:0000305',\n",
       " 'GO:0000306',\n",
       " 'GO:0000307',\n",
       " 'GO:0000308',\n",
       " 'GO:0000309',\n",
       " 'GO:0000310',\n",
       " 'GO:0000311',\n",
       " 'GO:0000312',\n",
       " 'GO:0000313',\n",
       " 'GO:0000314',\n",
       " 'GO:0000315',\n",
       " 'GO:0000316',\n",
       " 'GO:0000319',\n",
       " 'GO:0000320',\n",
       " 'GO:0000321',\n",
       " 'GO:0000322',\n",
       " 'GO:0000323',\n",
       " 'GO:0000324',\n",
       " 'GO:0000325',\n",
       " 'GO:0000326',\n",
       " 'GO:0000327',\n",
       " 'GO:0000328',\n",
       " 'GO:0000329',\n",
       " 'GO:0000330',\n",
       " 'GO:0000331',\n",
       " 'GO:0000332',\n",
       " 'GO:0000333',\n",
       " 'GO:0000334',\n",
       " 'GO:0000335',\n",
       " 'GO:0000336',\n",
       " 'GO:0000337',\n",
       " 'GO:0000338',\n",
       " 'GO:0000339',\n",
       " 'GO:0000340',\n",
       " 'GO:0000341',\n",
       " 'GO:0000342',\n",
       " 'GO:0000343',\n",
       " 'GO:0000344',\n",
       " 'GO:0000345',\n",
       " 'GO:0000346',\n",
       " 'GO:0000347',\n",
       " 'GO:0000348',\n",
       " 'GO:0000349',\n",
       " 'GO:0000350',\n",
       " 'GO:0000352',\n",
       " 'GO:0000353',\n",
       " 'GO:0000354',\n",
       " 'GO:0000362',\n",
       " 'GO:0000363',\n",
       " 'GO:0000364',\n",
       " 'GO:0000365',\n",
       " 'GO:0000366',\n",
       " 'GO:0000367',\n",
       " 'GO:0000372',\n",
       " 'GO:0000373',\n",
       " 'GO:0000374',\n",
       " 'GO:0000375',\n",
       " 'GO:0000376',\n",
       " 'GO:0000377',\n",
       " 'GO:0000378',\n",
       " 'GO:0000379',\n",
       " 'GO:0000380',\n",
       " 'GO:0000381',\n",
       " 'GO:0000384',\n",
       " 'GO:0000386',\n",
       " 'GO:0000387',\n",
       " 'GO:0000388',\n",
       " 'GO:0000389',\n",
       " 'GO:0000390',\n",
       " 'GO:0000393',\n",
       " 'GO:0000394',\n",
       " 'GO:0000395',\n",
       " 'GO:0000398',\n",
       " 'GO:0000399',\n",
       " 'GO:0000400',\n",
       " 'GO:0000401',\n",
       " 'GO:0000402',\n",
       " 'GO:0000403',\n",
       " 'GO:0000404',\n",
       " 'GO:0000405',\n",
       " 'GO:0000406',\n",
       " 'GO:0000407',\n",
       " 'GO:0000408',\n",
       " 'GO:0000409',\n",
       " 'GO:0000410',\n",
       " 'GO:0000411',\n",
       " 'GO:0000412',\n",
       " 'GO:0000413',\n",
       " 'GO:0000414',\n",
       " 'GO:0000415',\n",
       " 'GO:0000416',\n",
       " 'GO:0000417',\n",
       " 'GO:0000418',\n",
       " 'GO:0000419',\n",
       " 'GO:0000421',\n",
       " 'GO:0000422',\n",
       " 'GO:0000423',\n",
       " 'GO:0000424',\n",
       " 'GO:0000425',\n",
       " 'GO:0000426',\n",
       " 'GO:0000427',\n",
       " 'GO:0000428',\n",
       " 'GO:0000429',\n",
       " 'GO:0000430',\n",
       " 'GO:0000431',\n",
       " 'GO:0000432',\n",
       " 'GO:0000433',\n",
       " 'GO:0000434',\n",
       " 'GO:0000435',\n",
       " 'GO:0000436',\n",
       " 'GO:0000437',\n",
       " 'GO:0000438',\n",
       " 'GO:0000439',\n",
       " 'GO:0000440',\n",
       " 'GO:0000444',\n",
       " 'GO:0000445',\n",
       " 'GO:0000446',\n",
       " 'GO:0000447',\n",
       " 'GO:0000448',\n",
       " 'GO:0000449',\n",
       " 'GO:0000450',\n",
       " 'GO:0000451',\n",
       " 'GO:0000452',\n",
       " 'GO:0000453',\n",
       " 'GO:0000454',\n",
       " 'GO:0000455',\n",
       " 'GO:0000456',\n",
       " 'GO:0000457',\n",
       " 'GO:0000458',\n",
       " 'GO:0000459',\n",
       " 'GO:0000460',\n",
       " 'GO:0000461',\n",
       " 'GO:0000462',\n",
       " 'GO:0000463',\n",
       " 'GO:0000464',\n",
       " 'GO:0000465',\n",
       " 'GO:0000466',\n",
       " 'GO:0000467',\n",
       " 'GO:0000468',\n",
       " 'GO:0000469',\n",
       " 'GO:0000470',\n",
       " 'GO:0000471',\n",
       " 'GO:0000472',\n",
       " 'GO:0000473',\n",
       " 'GO:0000474',\n",
       " 'GO:0000475',\n",
       " 'GO:0000476',\n",
       " 'GO:0000477',\n",
       " 'GO:0000478',\n",
       " 'GO:0000479',\n",
       " 'GO:0000480',\n",
       " 'GO:0000481',\n",
       " 'GO:0000482',\n",
       " 'GO:0000483',\n",
       " 'GO:0000484',\n",
       " 'GO:0000485',\n",
       " 'GO:0000486',\n",
       " 'GO:0000487',\n",
       " 'GO:0000488',\n",
       " 'GO:0000489',\n",
       " 'GO:0000491',\n",
       " 'GO:0000492',\n",
       " 'GO:0000493',\n",
       " 'GO:0000494',\n",
       " 'GO:0000495',\n",
       " 'GO:0000497',\n",
       " 'GO:0000500',\n",
       " 'GO:0000502',\n",
       " 'GO:0000504',\n",
       " 'GO:0000506',\n",
       " 'GO:0000510',\n",
       " 'GO:0000511',\n",
       " 'GO:0000512',\n",
       " 'GO:0000513',\n",
       " 'GO:0000514',\n",
       " 'GO:0000515',\n",
       " 'GO:0000578',\n",
       " 'GO:0000700',\n",
       " 'GO:0000701',\n",
       " 'GO:0000702',\n",
       " 'GO:0000703',\n",
       " 'GO:0000704',\n",
       " 'GO:0000705',\n",
       " 'GO:0000706',\n",
       " 'GO:0000707',\n",
       " 'GO:0000708',\n",
       " 'GO:0000709',\n",
       " 'GO:0000710',\n",
       " 'GO:0000711',\n",
       " 'GO:0000712',\n",
       " 'GO:0000713',\n",
       " 'GO:0000714',\n",
       " 'GO:0000715',\n",
       " 'GO:0000716',\n",
       " 'GO:0000717',\n",
       " 'GO:0000718',\n",
       " 'GO:0000719',\n",
       " 'GO:0000720',\n",
       " 'GO:0000721',\n",
       " 'GO:0000722',\n",
       " 'GO:0000723',\n",
       " 'GO:0000724',\n",
       " 'GO:0000725',\n",
       " 'GO:0000726',\n",
       " 'GO:0000727',\n",
       " 'GO:0000729',\n",
       " 'GO:0000730',\n",
       " 'GO:0000731',\n",
       " 'GO:0000732',\n",
       " 'GO:0000733',\n",
       " 'GO:0000735',\n",
       " 'GO:0000736',\n",
       " 'GO:0000737',\n",
       " 'GO:0000738',\n",
       " 'GO:0000739',\n",
       " 'GO:0000740',\n",
       " 'GO:0000741',\n",
       " 'GO:0000742',\n",
       " 'GO:0000743',\n",
       " 'GO:0000744',\n",
       " 'GO:0000745',\n",
       " 'GO:0000746',\n",
       " 'GO:0000747',\n",
       " 'GO:0000748',\n",
       " 'GO:0000749',\n",
       " 'GO:0000750',\n",
       " 'GO:0000751',\n",
       " 'GO:0000752',\n",
       " 'GO:0000753',\n",
       " 'GO:0000754',\n",
       " 'GO:0000755',\n",
       " 'GO:0000756',\n",
       " 'GO:0000757',\n",
       " 'GO:0000758',\n",
       " 'GO:0000759',\n",
       " 'GO:0000760',\n",
       " 'GO:0000761',\n",
       " 'GO:0000762',\n",
       " 'GO:0000763',\n",
       " 'GO:0000764',\n",
       " 'GO:0000765',\n",
       " 'GO:0000766',\n",
       " 'GO:0000767',\n",
       " 'GO:0000768',\n",
       " 'GO:0000769',\n",
       " 'GO:0000770',\n",
       " 'GO:0000771',\n",
       " 'GO:0000772',\n",
       " 'GO:0000773',\n",
       " 'GO:0000774',\n",
       " 'GO:0000775',\n",
       " 'GO:0000776',\n",
       " 'GO:0000779',\n",
       " 'GO:0000781',\n",
       " 'GO:0000782',\n",
       " 'GO:0000783',\n",
       " 'GO:0000785',\n",
       " 'GO:0000786',\n",
       " 'GO:0000791',\n",
       " 'GO:0000792',\n",
       " 'GO:0000793',\n",
       " 'GO:0000794',\n",
       " 'GO:0000795',\n",
       " 'GO:0000796',\n",
       " 'GO:0000800',\n",
       " 'GO:0000801',\n",
       " 'GO:0000802',\n",
       " 'GO:0000803',\n",
       " 'GO:0000804',\n",
       " 'GO:0000805',\n",
       " 'GO:0000806',\n",
       " 'GO:0000807',\n",
       " 'GO:0000808',\n",
       " 'GO:0000809',\n",
       " 'GO:0000810',\n",
       " 'GO:0000811',\n",
       " 'GO:0000812',\n",
       " 'GO:0000813',\n",
       " 'GO:0000814',\n",
       " 'GO:0000815',\n",
       " 'GO:0000817',\n",
       " 'GO:0000819',\n",
       " 'GO:0000820',\n",
       " 'GO:0000821',\n",
       " 'GO:0000822',\n",
       " 'GO:0000823',\n",
       " 'GO:0000824',\n",
       " 'GO:0000825',\n",
       " 'GO:0000826',\n",
       " 'GO:0000827',\n",
       " 'GO:0000828',\n",
       " 'GO:0000829',\n",
       " 'GO:0000830',\n",
       " 'GO:0000831',\n",
       " 'GO:0000832',\n",
       " 'GO:0000833',\n",
       " 'GO:0000834',\n",
       " 'GO:0000835',\n",
       " 'GO:0000836',\n",
       " 'GO:0000837',\n",
       " 'GO:0000838',\n",
       " 'GO:0000839',\n",
       " 'GO:0000900',\n",
       " 'GO:0000901',\n",
       " 'GO:0000902',\n",
       " 'GO:0000903',\n",
       " 'GO:0000904',\n",
       " 'GO:0000905',\n",
       " 'GO:0000906',\n",
       " 'GO:0000907',\n",
       " 'GO:0000908',\n",
       " 'GO:0000909',\n",
       " 'GO:0000910',\n",
       " 'GO:0000911',\n",
       " 'GO:0000912',\n",
       " 'GO:0000913',\n",
       " 'GO:0000914',\n",
       " 'GO:0000915',\n",
       " 'GO:0000916',\n",
       " 'GO:0000917',\n",
       " 'GO:0000918',\n",
       " 'GO:0000919',\n",
       " 'GO:0000920',\n",
       " 'GO:0000921',\n",
       " 'GO:0000922',\n",
       " 'GO:0000923',\n",
       " 'GO:0000930',\n",
       " 'GO:0000931',\n",
       " 'GO:0000932',\n",
       " 'GO:0000933',\n",
       " 'GO:0000934',\n",
       " 'GO:0000935',\n",
       " 'GO:0000936',\n",
       " 'GO:0000937',\n",
       " 'GO:0000938',\n",
       " 'GO:0000939',\n",
       " 'GO:0000940',\n",
       " 'GO:0000943',\n",
       " 'GO:0000947',\n",
       " 'GO:0000948',\n",
       " 'GO:0000949',\n",
       " 'GO:0000950',\n",
       " 'GO:0000951',\n",
       " 'GO:0000952',\n",
       " 'GO:0000953',\n",
       " 'GO:0000954',\n",
       " 'GO:0000955',\n",
       " 'GO:0000956',\n",
       " 'GO:0000957',\n",
       " 'GO:0000958',\n",
       " 'GO:0000959',\n",
       " 'GO:0000960',\n",
       " 'GO:0000961',\n",
       " 'GO:0000962',\n",
       " 'GO:0000963',\n",
       " 'GO:0000964',\n",
       " 'GO:0000965',\n",
       " 'GO:0000966',\n",
       " 'GO:0000967',\n",
       " 'GO:0000968',\n",
       " 'GO:0000969',\n",
       " 'GO:0000970',\n",
       " 'GO:0000971',\n",
       " 'GO:0000972',\n",
       " 'GO:0000973',\n",
       " 'GO:0000974',\n",
       " 'GO:0000976',\n",
       " 'GO:0000977',\n",
       " 'GO:0000978',\n",
       " 'GO:0000979',\n",
       " 'GO:0000981',\n",
       " 'GO:0000987',\n",
       " 'GO:0000988',\n",
       " 'GO:0000989',\n",
       " 'GO:0000990',\n",
       " 'GO:0000991',\n",
       " 'GO:0000992',\n",
       " 'GO:0000993',\n",
       " 'GO:0000994',\n",
       " 'GO:0000995',\n",
       " 'GO:0001000',\n",
       " 'GO:0001001',\n",
       " 'GO:0001002',\n",
       " 'GO:0001003',\n",
       " 'GO:0001004',\n",
       " 'GO:0001006',\n",
       " 'GO:0001007',\n",
       " 'GO:0001010',\n",
       " 'GO:0001011',\n",
       " 'GO:0001014',\n",
       " 'GO:0001015',\n",
       " 'GO:0001016',\n",
       " 'GO:0001018',\n",
       " 'GO:0001019',\n",
       " 'GO:0001025',\n",
       " 'GO:0001026',\n",
       " 'GO:0001027',\n",
       " 'GO:0001028',\n",
       " 'GO:0001029',\n",
       " 'GO:0001039',\n",
       " 'GO:0001040',\n",
       " 'GO:0001042',\n",
       " 'GO:0001046',\n",
       " 'GO:0001048',\n",
       " 'GO:0001049',\n",
       " 'GO:0001050',\n",
       " 'GO:0001051',\n",
       " 'GO:0001052',\n",
       " 'GO:0001054',\n",
       " 'GO:0001055',\n",
       " 'GO:0001056',\n",
       " 'GO:0001057',\n",
       " 'GO:0001058',\n",
       " 'GO:0001059',\n",
       " 'GO:0001060',\n",
       " 'GO:0001061',\n",
       " 'GO:0001062',\n",
       " 'GO:0001063',\n",
       " 'GO:0001064',\n",
       " 'GO:0001065',\n",
       " 'GO:0001066',\n",
       " 'GO:0001067',\n",
       " 'GO:0001068',\n",
       " 'GO:0001069',\n",
       " 'GO:0001070',\n",
       " 'GO:0001072',\n",
       " 'GO:0001073',\n",
       " 'GO:0001074',\n",
       " 'GO:0001076',\n",
       " 'GO:0001079',\n",
       " 'GO:0001080',\n",
       " 'GO:0001081',\n",
       " 'GO:0001082',\n",
       " 'GO:0001083',\n",
       " 'GO:0001084',\n",
       " 'GO:0001086',\n",
       " 'GO:0001087',\n",
       " 'GO:0001088',\n",
       " 'GO:0001089',\n",
       " 'GO:0001090',\n",
       " 'GO:0001091',\n",
       " 'GO:0001092',\n",
       " 'GO:0001093',\n",
       " 'GO:0001094',\n",
       " 'GO:0001095',\n",
       " 'GO:0001096',\n",
       " 'GO:0001097',\n",
       " 'GO:0001098',\n",
       " 'GO:0001099',\n",
       " 'GO:0001100',\n",
       " 'GO:0001101',\n",
       " 'GO:0001108',\n",
       " 'GO:0001109',\n",
       " 'GO:0001110',\n",
       " 'GO:0001111',\n",
       " 'GO:0001112',\n",
       " 'GO:0001113',\n",
       " 'GO:0001114',\n",
       " 'GO:0001115',\n",
       " 'GO:0001116',\n",
       " 'GO:0001117',\n",
       " 'GO:0001118',\n",
       " 'GO:0001119',\n",
       " 'GO:0001120',\n",
       " 'GO:0001128',\n",
       " 'GO:0001129',\n",
       " 'GO:0001132',\n",
       " 'GO:0001134',\n",
       " 'GO:0001135',\n",
       " 'GO:0001139',\n",
       " 'GO:0001147',\n",
       " 'GO:0001149',\n",
       " 'GO:0001152',\n",
       " 'GO:0001153',\n",
       " 'GO:0001154',\n",
       " 'GO:0001155',\n",
       " 'GO:0001156',\n",
       " 'GO:0001161',\n",
       " 'GO:0001162',\n",
       " 'GO:0001163',\n",
       " 'GO:0001164',\n",
       " 'GO:0001165',\n",
       " 'GO:0001167',\n",
       " 'GO:0001168',\n",
       " 'GO:0001169',\n",
       " 'GO:0001170',\n",
       " 'GO:0001171',\n",
       " 'GO:0001172',\n",
       " 'GO:0001173',\n",
       " 'GO:0001174',\n",
       " 'GO:0001175',\n",
       " 'GO:0001177',\n",
       " 'GO:0001178',\n",
       " 'GO:0001179',\n",
       " 'GO:0001181',\n",
       " 'GO:0001182',\n",
       " 'GO:0001186',\n",
       " 'GO:0001188',\n",
       " 'GO:0001190',\n",
       " 'GO:0001191',\n",
       " 'GO:0001192',\n",
       " 'GO:0001193',\n",
       " 'GO:0001195',\n",
       " 'GO:0001196',\n",
       " 'GO:0001197',\n",
       " 'GO:0001198',\n",
       " 'GO:0001207',\n",
       " 'GO:0001208',\n",
       " 'GO:0001216',\n",
       " 'GO:0001217',\n",
       " 'GO:0001221',\n",
       " 'GO:0001222',\n",
       " 'GO:0001223',\n",
       " 'GO:0001227',\n",
       " 'GO:0001228',\n",
       " 'GO:0001300',\n",
       " 'GO:0001301',\n",
       " 'GO:0001302',\n",
       " 'GO:0001303',\n",
       " 'GO:0001304',\n",
       " 'GO:0001305',\n",
       " 'GO:0001306',\n",
       " 'GO:0001307',\n",
       " 'GO:0001308',\n",
       " 'GO:0001309',\n",
       " 'GO:0001310',\n",
       " 'GO:0001311',\n",
       " 'GO:0001312',\n",
       " 'GO:0001313',\n",
       " 'GO:0001314',\n",
       " 'GO:0001315',\n",
       " 'GO:0001316',\n",
       " 'GO:0001317',\n",
       " 'GO:0001318',\n",
       " 'GO:0001319',\n",
       " 'GO:0001320',\n",
       " 'GO:0001321',\n",
       " 'GO:0001322',\n",
       " 'GO:0001323',\n",
       " 'GO:0001324',\n",
       " 'GO:0001325',\n",
       " 'GO:0001326',\n",
       " 'GO:0001400',\n",
       " 'GO:0001401',\n",
       " 'GO:0001402',\n",
       " 'GO:0001403',\n",
       " 'GO:0001404',\n",
       " 'GO:0001405',\n",
       " 'GO:0001406',\n",
       " 'GO:0001407',\n",
       " 'GO:0001408',\n",
       " 'GO:0001409',\n",
       " 'GO:0001410',\n",
       " 'GO:0001411',\n",
       " 'GO:0001501',\n",
       " 'GO:0001502',\n",
       " 'GO:0001503',\n",
       " 'GO:0001504',\n",
       " 'GO:0001505',\n",
       " 'GO:0001506',\n",
       " 'GO:0001507',\n",
       " 'GO:0001508',\n",
       " 'GO:0001509',\n",
       " 'GO:0001510',\n",
       " 'GO:0001511',\n",
       " 'GO:0001512',\n",
       " 'GO:0001514',\n",
       " 'GO:0001515',\n",
       " 'GO:0001516',\n",
       " 'GO:0001517',\n",
       " 'GO:0001518',\n",
       " 'GO:0001519',\n",
       " 'GO:0001520',\n",
       " 'GO:0001522',\n",
       " 'GO:0001523',\n",
       " 'GO:0001524',\n",
       " 'GO:0001525',\n",
       " 'GO:0001526',\n",
       " 'GO:0001527',\n",
       " 'GO:0001528',\n",
       " 'GO:0001529',\n",
       " 'GO:0001530',\n",
       " 'GO:0001531',\n",
       " 'GO:0001532',\n",
       " 'GO:0001533',\n",
       " 'GO:0001534',\n",
       " 'GO:0001535',\n",
       " 'GO:0001536',\n",
       " 'GO:0001537',\n",
       " 'GO:0001539',\n",
       " 'GO:0001540',\n",
       " 'GO:0001541',\n",
       " 'GO:0001542',\n",
       " 'GO:0001543',\n",
       " 'GO:0001544',\n",
       " 'GO:0001545',\n",
       " 'GO:0001546',\n",
       " 'GO:0001547',\n",
       " 'GO:0001548',\n",
       " 'GO:0001549',\n",
       " 'GO:0001550',\n",
       " 'GO:0001551',\n",
       " 'GO:0001552',\n",
       " 'GO:0001553',\n",
       " 'GO:0001554',\n",
       " 'GO:0001555',\n",
       " 'GO:0001556',\n",
       " 'GO:0001557',\n",
       " 'GO:0001558',\n",
       " 'GO:0001559',\n",
       " 'GO:0001560',\n",
       " 'GO:0001561',\n",
       " 'GO:0001562',\n",
       " 'GO:0001563',\n",
       " 'GO:0001564',\n",
       " 'GO:0001565',\n",
       " 'GO:0001566',\n",
       " 'GO:0001567',\n",
       " 'GO:0001568',\n",
       " 'GO:0001569',\n",
       " 'GO:0001570',\n",
       " 'GO:0001571',\n",
       " 'GO:0001572',\n",
       " 'GO:0001573',\n",
       " 'GO:0001574',\n",
       " 'GO:0001575',\n",
       " 'GO:0001576',\n",
       " 'GO:0001577',\n",
       " 'GO:0001578',\n",
       " 'GO:0001579',\n",
       " 'GO:0001580',\n",
       " 'GO:0001581',\n",
       " 'GO:0001582',\n",
       " 'GO:0001583',\n",
       " 'GO:0001584',\n",
       " 'GO:0001586',\n",
       " 'GO:0001587',\n",
       " 'GO:0001588',\n",
       " 'GO:0001591',\n",
       " 'GO:0001594',\n",
       " 'GO:0001595',\n",
       " 'GO:0001596',\n",
       " 'GO:0001597',\n",
       " 'GO:0001598',\n",
       " 'GO:0001601',\n",
       " 'GO:0001602',\n",
       " 'GO:0001603',\n",
       " 'GO:0001604',\n",
       " 'GO:0001605',\n",
       " 'GO:0001606',\n",
       " 'GO:0001607',\n",
       " 'GO:0001608',\n",
       " 'GO:0001609',\n",
       " 'GO:0001614',\n",
       " 'GO:0001615',\n",
       " 'GO:0001616',\n",
       " 'GO:0001617',\n",
       " 'GO:0001618',\n",
       " 'GO:0001619',\n",
       " 'GO:0001621',\n",
       " 'GO:0001626',\n",
       " 'GO:0001627',\n",
       " 'GO:0001628',\n",
       " 'GO:0001629',\n",
       " 'GO:0001630',\n",
       " 'GO:0001631',\n",
       " 'GO:0001632',\n",
       " 'GO:0001633',\n",
       " 'GO:0001634',\n",
       " 'GO:0001635',\n",
       " 'GO:0001636',\n",
       " 'GO:0001637',\n",
       " 'GO:0001639',\n",
       " 'GO:0001640',\n",
       " 'GO:0001641',\n",
       " 'GO:0001642',\n",
       " 'GO:0001646',\n",
       " 'GO:0001647',\n",
       " 'GO:0001648',\n",
       " 'GO:0001649',\n",
       " 'GO:0001650',\n",
       " 'GO:0001651',\n",
       " 'GO:0001652',\n",
       " 'GO:0001653',\n",
       " 'GO:0001654',\n",
       " 'GO:0001655',\n",
       " 'GO:0001656',\n",
       " 'GO:0001657',\n",
       " 'GO:0001658',\n",
       " 'GO:0001659',\n",
       " 'GO:0001660',\n",
       " 'GO:0001661',\n",
       " 'GO:0001662',\n",
       " 'GO:0001664',\n",
       " 'GO:0001665',\n",
       " 'GO:0001666',\n",
       " 'GO:0001667',\n",
       " 'GO:0001669',\n",
       " 'GO:0001671',\n",
       " 'GO:0001673',\n",
       " 'GO:0001674',\n",
       " 'GO:0001675',\n",
       " 'GO:0001676',\n",
       " 'GO:0001677',\n",
       " 'GO:0001678',\n",
       " 'GO:0001680',\n",
       " 'GO:0001681',\n",
       " 'GO:0001682',\n",
       " 'GO:0001683',\n",
       " 'GO:0001684',\n",
       " 'GO:0001685',\n",
       " 'GO:0001686',\n",
       " 'GO:0001687',\n",
       " 'GO:0001688',\n",
       " 'GO:0001689',\n",
       " 'GO:0001690',\n",
       " 'GO:0001691',\n",
       " 'GO:0001692',\n",
       " 'GO:0001694',\n",
       " 'GO:0001695',\n",
       " 'GO:0001696',\n",
       " 'GO:0001697',\n",
       " 'GO:0001698',\n",
       " 'GO:0001699',\n",
       " 'GO:0001700',\n",
       " 'GO:0001701',\n",
       " 'GO:0001702',\n",
       " 'GO:0001703',\n",
       " 'GO:0001704',\n",
       " 'GO:0001705',\n",
       " 'GO:0001706',\n",
       " 'GO:0001707',\n",
       " 'GO:0001708',\n",
       " 'GO:0001709',\n",
       " 'GO:0001710',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_term_list = df['Def Summary'].to_list()\n",
    "go_term_name = df['GO Term ID'].to_list()\n",
    "go_term_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a pretrained model from a state dictionary ...\n",
      "Tokenization ...\n",
      "Tokenization Done.\n",
      "Get Embeddings ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [05:09<00:00, 12.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47595, 768])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>-1.168093</td>\n",
       "      <td>-0.355214</td>\n",
       "      <td>0.265877</td>\n",
       "      <td>-0.710051</td>\n",
       "      <td>0.515028</td>\n",
       "      <td>-0.525165</td>\n",
       "      <td>-0.186588</td>\n",
       "      <td>-0.161192</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.350874</td>\n",
       "      <td>-0.991801</td>\n",
       "      <td>-0.648123</td>\n",
       "      <td>-0.361629</td>\n",
       "      <td>-0.914965</td>\n",
       "      <td>-0.506993</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>0.207266</td>\n",
       "      <td>0.070705</td>\n",
       "      <td>0.938594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>-1.185879</td>\n",
       "      <td>-0.098765</td>\n",
       "      <td>0.388240</td>\n",
       "      <td>-0.295556</td>\n",
       "      <td>0.327296</td>\n",
       "      <td>-0.119842</td>\n",
       "      <td>0.399882</td>\n",
       "      <td>-0.035890</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086927</td>\n",
       "      <td>-0.842870</td>\n",
       "      <td>-0.385764</td>\n",
       "      <td>0.175797</td>\n",
       "      <td>-1.223772</td>\n",
       "      <td>-0.999628</td>\n",
       "      <td>0.101473</td>\n",
       "      <td>-0.051212</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>0.780469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000003</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>-0.199995</td>\n",
       "      <td>0.151511</td>\n",
       "      <td>-0.942141</td>\n",
       "      <td>0.109313</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.633298</td>\n",
       "      <td>0.507875</td>\n",
       "      <td>0.665548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174185</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.119273</td>\n",
       "      <td>-0.295167</td>\n",
       "      <td>-0.331179</td>\n",
       "      <td>0.102570</td>\n",
       "      <td>-0.524301</td>\n",
       "      <td>-0.139264</td>\n",
       "      <td>0.761573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000005</td>\n",
       "      <td>0.163135</td>\n",
       "      <td>0.301527</td>\n",
       "      <td>0.219680</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>-0.129769</td>\n",
       "      <td>0.225696</td>\n",
       "      <td>0.357577</td>\n",
       "      <td>0.819992</td>\n",
       "      <td>0.852388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084025</td>\n",
       "      <td>-0.291103</td>\n",
       "      <td>-0.003621</td>\n",
       "      <td>0.245929</td>\n",
       "      <td>-0.443244</td>\n",
       "      <td>0.229245</td>\n",
       "      <td>-0.685159</td>\n",
       "      <td>-0.725621</td>\n",
       "      <td>0.285964</td>\n",
       "      <td>0.313210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>-0.641113</td>\n",
       "      <td>-0.541363</td>\n",
       "      <td>0.413941</td>\n",
       "      <td>0.699345</td>\n",
       "      <td>0.461507</td>\n",
       "      <td>-0.497388</td>\n",
       "      <td>-0.044589</td>\n",
       "      <td>-0.655766</td>\n",
       "      <td>-0.596647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561434</td>\n",
       "      <td>0.246475</td>\n",
       "      <td>-0.029871</td>\n",
       "      <td>-0.212828</td>\n",
       "      <td>-0.985273</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.582681</td>\n",
       "      <td>0.299317</td>\n",
       "      <td>-0.131577</td>\n",
       "      <td>0.739702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>GO:2001313</td>\n",
       "      <td>0.174428</td>\n",
       "      <td>0.194728</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>-0.713190</td>\n",
       "      <td>-0.272055</td>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.129901</td>\n",
       "      <td>-0.983496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.429651</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.464941</td>\n",
       "      <td>-0.740187</td>\n",
       "      <td>0.179149</td>\n",
       "      <td>-0.960807</td>\n",
       "      <td>-0.746958</td>\n",
       "      <td>1.069112</td>\n",
       "      <td>-0.848182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47591</th>\n",
       "      <td>GO:2001314</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.306214</td>\n",
       "      <td>-0.254303</td>\n",
       "      <td>0.253673</td>\n",
       "      <td>-0.533680</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>0.150939</td>\n",
       "      <td>-0.229323</td>\n",
       "      <td>-1.078991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042979</td>\n",
       "      <td>0.134560</td>\n",
       "      <td>-0.356661</td>\n",
       "      <td>-0.381828</td>\n",
       "      <td>-0.638337</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>-0.788312</td>\n",
       "      <td>-0.683442</td>\n",
       "      <td>1.087031</td>\n",
       "      <td>-0.593092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47592</th>\n",
       "      <td>GO:2001315</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>0.241391</td>\n",
       "      <td>-0.227353</td>\n",
       "      <td>0.317366</td>\n",
       "      <td>-0.726656</td>\n",
       "      <td>-0.197968</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>-0.954113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349853</td>\n",
       "      <td>0.370059</td>\n",
       "      <td>-0.144607</td>\n",
       "      <td>-0.493184</td>\n",
       "      <td>-0.655063</td>\n",
       "      <td>0.217335</td>\n",
       "      <td>-0.841272</td>\n",
       "      <td>-0.821077</td>\n",
       "      <td>1.036363</td>\n",
       "      <td>-0.836614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47593</th>\n",
       "      <td>GO:2001316</td>\n",
       "      <td>0.139543</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>0.576852</td>\n",
       "      <td>0.330342</td>\n",
       "      <td>0.916943</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>-0.020316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354748</td>\n",
       "      <td>-0.083168</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>-0.663565</td>\n",
       "      <td>0.543016</td>\n",
       "      <td>-0.652230</td>\n",
       "      <td>-1.427881</td>\n",
       "      <td>-0.985257</td>\n",
       "      <td>1.673561</td>\n",
       "      <td>0.109659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47594</th>\n",
       "      <td>GO:2001317</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>0.090899</td>\n",
       "      <td>0.888541</td>\n",
       "      <td>0.309920</td>\n",
       "      <td>0.403966</td>\n",
       "      <td>0.202783</td>\n",
       "      <td>0.706517</td>\n",
       "      <td>-0.017584</td>\n",
       "      <td>-0.171057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544680</td>\n",
       "      <td>-0.046654</td>\n",
       "      <td>0.262865</td>\n",
       "      <td>-0.767305</td>\n",
       "      <td>0.753788</td>\n",
       "      <td>-0.577503</td>\n",
       "      <td>-1.194909</td>\n",
       "      <td>-0.799556</td>\n",
       "      <td>1.519368</td>\n",
       "      <td>0.263210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47595 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Disease name         0         1         2         3         4  \\\n",
       "0       GO:0000001 -1.168093 -0.355214  0.265877 -0.710051  0.515028   \n",
       "1       GO:0000002 -1.185879 -0.098765  0.388240 -0.295556  0.327296   \n",
       "2       GO:0000003  0.063323 -0.199995  0.151511 -0.942141  0.109313   \n",
       "3       GO:0000005  0.163135  0.301527  0.219680  0.094342 -0.129769   \n",
       "4       GO:0000006 -0.641113 -0.541363  0.413941  0.699345  0.461507   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "47590   GO:2001313  0.174428  0.194728 -0.284376  0.282102 -0.713190   \n",
       "47591   GO:2001314  0.025886  0.306214 -0.254303  0.253673 -0.533680   \n",
       "47592   GO:2001315  0.027134  0.241391 -0.227353  0.317366 -0.726656   \n",
       "47593   GO:2001316  0.139543  0.028883  0.899480  0.152932  0.576852   \n",
       "47594   GO:2001317  0.083064  0.090899  0.888541  0.309920  0.403966   \n",
       "\n",
       "              5         6         7         8  ...       758       759  \\\n",
       "0     -0.525165 -0.186588 -0.161192  0.186984  ... -1.350874 -0.991801   \n",
       "1     -0.119842  0.399882 -0.035890  0.853417  ... -1.086927 -0.842870   \n",
       "2      0.015316  0.633298  0.507875  0.665548  ...  0.174185  0.351648   \n",
       "3      0.225696  0.357577  0.819992  0.852388  ... -0.084025 -0.291103   \n",
       "4     -0.497388 -0.044589 -0.655766 -0.596647  ... -0.561434  0.246475   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "47590 -0.272055  0.121190  0.129901 -0.983496  ...  0.500545  0.429651   \n",
       "47591 -0.269355  0.150939 -0.229323 -1.078991  ...  0.042979  0.134560   \n",
       "47592 -0.197968  0.045653  0.038912 -0.954113  ...  0.349853  0.370059   \n",
       "47593  0.330342  0.916943  0.012306 -0.020316  ... -0.354748 -0.083168   \n",
       "47594  0.202783  0.706517 -0.017584 -0.171057  ... -0.544680 -0.046654   \n",
       "\n",
       "            760       761       762       763       764       765       766  \\\n",
       "0     -0.648123 -0.361629 -0.914965 -0.506993  0.389760  0.207266  0.070705   \n",
       "1     -0.385764  0.175797 -1.223772 -0.999628  0.101473 -0.051212  0.048775   \n",
       "2      0.138497  0.119273 -0.295167 -0.331179  0.102570 -0.524301 -0.139264   \n",
       "3     -0.003621  0.245929 -0.443244  0.229245 -0.685159 -0.725621  0.285964   \n",
       "4     -0.029871 -0.212828 -0.985273  0.677472  0.582681  0.299317 -0.131577   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47590 -0.292929 -0.464941 -0.740187  0.179149 -0.960807 -0.746958  1.069112   \n",
       "47591 -0.356661 -0.381828 -0.638337  0.077176 -0.788312 -0.683442  1.087031   \n",
       "47592 -0.144607 -0.493184 -0.655063  0.217335 -0.841272 -0.821077  1.036363   \n",
       "47593  0.043640 -0.663565  0.543016 -0.652230 -1.427881 -0.985257  1.673561   \n",
       "47594  0.262865 -0.767305  0.753788 -0.577503 -1.194909 -0.799556  1.519368   \n",
       "\n",
       "            767  \n",
       "0      0.938594  \n",
       "1      0.780469  \n",
       "2      0.761573  \n",
       "3      0.313210  \n",
       "4      0.739702  \n",
       "...         ...  \n",
       "47590 -0.848182  \n",
       "47591 -0.593092  \n",
       "47592 -0.836614  \n",
       "47593  0.109659  \n",
       "47594  0.263210  \n",
       "\n",
       "[47595 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>-1.168093</td>\n",
       "      <td>-0.355214</td>\n",
       "      <td>0.265877</td>\n",
       "      <td>-0.710051</td>\n",
       "      <td>0.515028</td>\n",
       "      <td>-0.525165</td>\n",
       "      <td>-0.186588</td>\n",
       "      <td>-0.161192</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.350874</td>\n",
       "      <td>-0.991801</td>\n",
       "      <td>-0.648123</td>\n",
       "      <td>-0.361629</td>\n",
       "      <td>-0.914965</td>\n",
       "      <td>-0.506993</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>0.207266</td>\n",
       "      <td>0.070705</td>\n",
       "      <td>0.938594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>-1.185879</td>\n",
       "      <td>-0.098765</td>\n",
       "      <td>0.388240</td>\n",
       "      <td>-0.295556</td>\n",
       "      <td>0.327296</td>\n",
       "      <td>-0.119842</td>\n",
       "      <td>0.399882</td>\n",
       "      <td>-0.035890</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086927</td>\n",
       "      <td>-0.842870</td>\n",
       "      <td>-0.385764</td>\n",
       "      <td>0.175797</td>\n",
       "      <td>-1.223772</td>\n",
       "      <td>-0.999628</td>\n",
       "      <td>0.101473</td>\n",
       "      <td>-0.051212</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>0.780469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000003</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>-0.199995</td>\n",
       "      <td>0.151511</td>\n",
       "      <td>-0.942141</td>\n",
       "      <td>0.109313</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.633298</td>\n",
       "      <td>0.507875</td>\n",
       "      <td>0.665548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174185</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.119273</td>\n",
       "      <td>-0.295167</td>\n",
       "      <td>-0.331179</td>\n",
       "      <td>0.102570</td>\n",
       "      <td>-0.524301</td>\n",
       "      <td>-0.139264</td>\n",
       "      <td>0.761573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000005</td>\n",
       "      <td>0.163135</td>\n",
       "      <td>0.301527</td>\n",
       "      <td>0.219680</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>-0.129769</td>\n",
       "      <td>0.225696</td>\n",
       "      <td>0.357577</td>\n",
       "      <td>0.819992</td>\n",
       "      <td>0.852388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084025</td>\n",
       "      <td>-0.291103</td>\n",
       "      <td>-0.003621</td>\n",
       "      <td>0.245929</td>\n",
       "      <td>-0.443244</td>\n",
       "      <td>0.229245</td>\n",
       "      <td>-0.685159</td>\n",
       "      <td>-0.725621</td>\n",
       "      <td>0.285964</td>\n",
       "      <td>0.313210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>-0.641113</td>\n",
       "      <td>-0.541363</td>\n",
       "      <td>0.413941</td>\n",
       "      <td>0.699345</td>\n",
       "      <td>0.461507</td>\n",
       "      <td>-0.497388</td>\n",
       "      <td>-0.044589</td>\n",
       "      <td>-0.655766</td>\n",
       "      <td>-0.596647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561434</td>\n",
       "      <td>0.246475</td>\n",
       "      <td>-0.029871</td>\n",
       "      <td>-0.212828</td>\n",
       "      <td>-0.985273</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.582681</td>\n",
       "      <td>0.299317</td>\n",
       "      <td>-0.131577</td>\n",
       "      <td>0.739702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>GO:2001313</td>\n",
       "      <td>0.174428</td>\n",
       "      <td>0.194728</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>-0.713190</td>\n",
       "      <td>-0.272055</td>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.129901</td>\n",
       "      <td>-0.983496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.429651</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.464941</td>\n",
       "      <td>-0.740187</td>\n",
       "      <td>0.179149</td>\n",
       "      <td>-0.960807</td>\n",
       "      <td>-0.746958</td>\n",
       "      <td>1.069112</td>\n",
       "      <td>-0.848182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47591</th>\n",
       "      <td>GO:2001314</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.306214</td>\n",
       "      <td>-0.254303</td>\n",
       "      <td>0.253673</td>\n",
       "      <td>-0.533680</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>0.150939</td>\n",
       "      <td>-0.229323</td>\n",
       "      <td>-1.078991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042979</td>\n",
       "      <td>0.134560</td>\n",
       "      <td>-0.356661</td>\n",
       "      <td>-0.381828</td>\n",
       "      <td>-0.638337</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>-0.788312</td>\n",
       "      <td>-0.683442</td>\n",
       "      <td>1.087031</td>\n",
       "      <td>-0.593092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47592</th>\n",
       "      <td>GO:2001315</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>0.241391</td>\n",
       "      <td>-0.227353</td>\n",
       "      <td>0.317366</td>\n",
       "      <td>-0.726656</td>\n",
       "      <td>-0.197968</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>-0.954113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349853</td>\n",
       "      <td>0.370059</td>\n",
       "      <td>-0.144607</td>\n",
       "      <td>-0.493184</td>\n",
       "      <td>-0.655063</td>\n",
       "      <td>0.217335</td>\n",
       "      <td>-0.841272</td>\n",
       "      <td>-0.821077</td>\n",
       "      <td>1.036363</td>\n",
       "      <td>-0.836614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47593</th>\n",
       "      <td>GO:2001316</td>\n",
       "      <td>0.139543</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>0.576852</td>\n",
       "      <td>0.330342</td>\n",
       "      <td>0.916943</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>-0.020316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354748</td>\n",
       "      <td>-0.083168</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>-0.663565</td>\n",
       "      <td>0.543016</td>\n",
       "      <td>-0.652230</td>\n",
       "      <td>-1.427881</td>\n",
       "      <td>-0.985257</td>\n",
       "      <td>1.673561</td>\n",
       "      <td>0.109659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47594</th>\n",
       "      <td>GO:2001317</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>0.090899</td>\n",
       "      <td>0.888541</td>\n",
       "      <td>0.309920</td>\n",
       "      <td>0.403966</td>\n",
       "      <td>0.202783</td>\n",
       "      <td>0.706517</td>\n",
       "      <td>-0.017584</td>\n",
       "      <td>-0.171057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544680</td>\n",
       "      <td>-0.046654</td>\n",
       "      <td>0.262865</td>\n",
       "      <td>-0.767305</td>\n",
       "      <td>0.753788</td>\n",
       "      <td>-0.577503</td>\n",
       "      <td>-1.194909</td>\n",
       "      <td>-0.799556</td>\n",
       "      <td>1.519368</td>\n",
       "      <td>0.263210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47595 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Disease name         0         1         2         3         4  \\\n",
       "0       GO:0000001 -1.168093 -0.355214  0.265877 -0.710051  0.515028   \n",
       "1       GO:0000002 -1.185879 -0.098765  0.388240 -0.295556  0.327296   \n",
       "2       GO:0000003  0.063323 -0.199995  0.151511 -0.942141  0.109313   \n",
       "3       GO:0000005  0.163135  0.301527  0.219680  0.094342 -0.129769   \n",
       "4       GO:0000006 -0.641113 -0.541363  0.413941  0.699345  0.461507   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "47590   GO:2001313  0.174428  0.194728 -0.284376  0.282102 -0.713190   \n",
       "47591   GO:2001314  0.025886  0.306214 -0.254303  0.253673 -0.533680   \n",
       "47592   GO:2001315  0.027134  0.241391 -0.227353  0.317366 -0.726656   \n",
       "47593   GO:2001316  0.139543  0.028883  0.899480  0.152932  0.576852   \n",
       "47594   GO:2001317  0.083064  0.090899  0.888541  0.309920  0.403966   \n",
       "\n",
       "              5         6         7         8  ...       758       759  \\\n",
       "0     -0.525165 -0.186588 -0.161192  0.186984  ... -1.350874 -0.991801   \n",
       "1     -0.119842  0.399882 -0.035890  0.853417  ... -1.086927 -0.842870   \n",
       "2      0.015316  0.633298  0.507875  0.665548  ...  0.174185  0.351648   \n",
       "3      0.225696  0.357577  0.819992  0.852388  ... -0.084025 -0.291103   \n",
       "4     -0.497388 -0.044589 -0.655766 -0.596647  ... -0.561434  0.246475   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "47590 -0.272055  0.121190  0.129901 -0.983496  ...  0.500545  0.429651   \n",
       "47591 -0.269355  0.150939 -0.229323 -1.078991  ...  0.042979  0.134560   \n",
       "47592 -0.197968  0.045653  0.038912 -0.954113  ...  0.349853  0.370059   \n",
       "47593  0.330342  0.916943  0.012306 -0.020316  ... -0.354748 -0.083168   \n",
       "47594  0.202783  0.706517 -0.017584 -0.171057  ... -0.544680 -0.046654   \n",
       "\n",
       "            760       761       762       763       764       765       766  \\\n",
       "0     -0.648123 -0.361629 -0.914965 -0.506993  0.389760  0.207266  0.070705   \n",
       "1     -0.385764  0.175797 -1.223772 -0.999628  0.101473 -0.051212  0.048775   \n",
       "2      0.138497  0.119273 -0.295167 -0.331179  0.102570 -0.524301 -0.139264   \n",
       "3     -0.003621  0.245929 -0.443244  0.229245 -0.685159 -0.725621  0.285964   \n",
       "4     -0.029871 -0.212828 -0.985273  0.677472  0.582681  0.299317 -0.131577   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47590 -0.292929 -0.464941 -0.740187  0.179149 -0.960807 -0.746958  1.069112   \n",
       "47591 -0.356661 -0.381828 -0.638337  0.077176 -0.788312 -0.683442  1.087031   \n",
       "47592 -0.144607 -0.493184 -0.655063  0.217335 -0.841272 -0.821077  1.036363   \n",
       "47593  0.043640 -0.663565  0.543016 -0.652230 -1.427881 -0.985257  1.673561   \n",
       "47594  0.262865 -0.767305  0.753788 -0.577503 -1.194909 -0.799556  1.519368   \n",
       "\n",
       "            767  \n",
       "0      0.938594  \n",
       "1      0.780469  \n",
       "2      0.761573  \n",
       "3      0.313210  \n",
       "4      0.739702  \n",
       "...         ...  \n",
       "47590 -0.848182  \n",
       "47591 -0.593092  \n",
       "47592 -0.836614  \n",
       "47593  0.109659  \n",
       "47594  0.263210  \n",
       "\n",
       "[47595 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def predict_pathway(gene_names,  gene_text):\n",
    "   \n",
    "    # Load your model and get embeddings\n",
    "    loaded_model = torch.load(\"state_dict_0.pth\")\n",
    "    embed = getEmbeddings(gene_text, loaded_model, batch_size=2000).detach().cpu().numpy()\n",
    "    \n",
    "    # Create a DataFrame to map gene names to embeddings\n",
    "    embeddings_df = pd.DataFrame(embed, index=gene_names)\n",
    "    embeddings_df.reset_index(inplace=True)\n",
    "    embeddings_df.rename(columns={'index': 'Disease name'}, inplace=True)\n",
    "    \n",
    "    # Now, embeddings_df contains each gene name and its corresponding embedding\n",
    "    display(embeddings_df)\n",
    "    return embeddings_df\n",
    "\n",
    "    # Optional: Save the embeddings DataFrame to a CSV file\n",
    "    \n",
    "\n",
    "embeddings_df = predict_pathway(go_term_name, go_term_list)\n",
    "embeddings_df.to_csv(\"go_terms_embeddings.csv\", index=False)\n",
    "display(embeddings_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
